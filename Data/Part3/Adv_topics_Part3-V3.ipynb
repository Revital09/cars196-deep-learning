{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5ab4caa-bdeb-4b2e-9c86-249051a669a9",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(17, 116, 155);text-align:left;font-size:250%;font-family:verdana;text-decoration:underline;\"> \n",
    "    Advanced topics - Final Project - Part 3: End-to-End CNN</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efbbb25-fe9c-454b-bf0f-d6484f12e3cd",
   "metadata": {},
   "source": [
    "## <u>פונקציית הפסד: שימוש ב-Focal Loss</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8cc0cd-f383-4cd0-bc2e-3285c12b2661",
   "metadata": {},
   "source": [
    "## <u>Imports</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68399c62-7323-4d76-8ce9-e0b83824a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24211b00-91e2-4d41-83b9-3a35b28efd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# קביעת התקן (GPU אם קיים)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ea9bea-8f37-4824-b77c-f54ed44d9947",
   "metadata": {},
   "source": [
    "## <u>Load and Preprocess Dataset</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28b29a1c-dc42-4ed5-9b93-bb9426860437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Cars196 dataset from TFRecord files...\n",
      "Loaded 8144 training images and 8041 test images.\n"
     ]
    }
   ],
   "source": [
    "# טעינת הנתונים (TFRecord) והכנה לפורמט PyTorch\n",
    "print(\"Loading Cars196 dataset from TFRecord files...\")\n",
    "\n",
    "data_dir = r\"C:\\Users\\yifat\\Data Science\\נושאים מתקדמים\\Final_Project_Shay\\cars196\"\n",
    "\n",
    "# יצירת רשימת קבצי ה-TFRecord\n",
    "train_files = [os.path.join(data_dir, f\"cars196-train.tfrecord-0000{i}-of-00008\") for i in range(8)]\n",
    "test_files = [os.path.join(data_dir, f\"cars196-test.tfrecord-0000{i}-of-00008\") for i in range(8)]\n",
    "\n",
    "# פונקציה לקריאת TFRecord\n",
    "def parse_tfrecord(example):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    parsed_example = tf.io.parse_single_example(example, feature_description)\n",
    "    image = tf.image.decode_jpeg(parsed_example['image'], channels=3)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    label = parsed_example['label']\n",
    "    return image, label\n",
    "\n",
    "def load_tfrecord_dataset(filenames):\n",
    "    raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = raw_dataset.map(parse_tfrecord)\n",
    "    return list(dataset)  # ממירים לרשימה לשימוש ב-PyTorch\n",
    "\n",
    "# טעינת ה-Train/Test מ-TFRecord\n",
    "train_data = [(image.numpy().astype('uint8'), label.numpy()) for image, label in load_tfrecord_dataset(train_files)]\n",
    "test_data = [(image.numpy().astype('uint8'), label.numpy()) for image, label in load_tfrecord_dataset(test_files)]\n",
    "\n",
    "print(f\"Loaded {len(train_data)} training images and {len(test_data)} test images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fbc8aa-92ef-447d-af0d-b1312d8d9292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# מחלקת Dataset לטעינת הנתונים\n",
    "class Cars196Dataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_np, label = self.data[idx]\n",
    "        image = Image.fromarray(image_np)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c06a716-0100-4db0-baea-1457b189d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ניסיון עם אוגמנטציה פחות אגרסיבית\n",
    "# הפחתת רמת ה-ColorJitter והאוגמנטציות הגורמות לעיוותים גדולים כמו RandomPerspective ו-RandomAffine\n",
    "# הימנעות מיותר מדי RandomErasing, שכן זה יכול לגרום לאיבוד מידע חשוב\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb725ff1-c3d5-464a-9cab-0c439329eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # היפוך אופקי\n",
    "    transforms.RandomRotation(10),  # הקטנת סיבוב ל-10 מעלות\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),  # הקטנת שינויי הצבעים\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # פחות חיתוך\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# סט הבדיקה ללא אוגמנטציה\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28dbf99e-0ea1-4878-a1da-49acb5dfffe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test Dataloaders created with batch size 32.\n",
      "Training samples: 8144, Testing samples: 8041\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_dataset = Cars196Dataset(train_data, transform=train_transform)\n",
    "test_dataset = Cars196Dataset(test_data, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Train and Test Dataloaders created with batch size {batch_size}.\")\n",
    "print(f\"Training samples: {len(train_dataset)}, Testing samples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ba7bed-4afe-4839-9679-eb9ec0280ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# חישוב משקלים למחלקות לטיפול בחוסר איזון\n",
    "labels_list = [label for _, label in train_data]\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels_list), y=labels_list)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# פונקציית הפסד משופרת: שימוש ב-Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=1):  # שימוש בערכים קבועים\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = self.ce_loss(inputs, targets)\n",
    "        p_t = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad66359-9706-4558-9b71-27eac9627f6f",
   "metadata": {},
   "source": [
    "## <u>Define and Train a CNN Model</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7253cfb6-86c3-4848-8087-ccf6b37ed0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# הוספת שכבות קונבולוציה כדי להגדיל את עומק הרשת\n",
    "# Batch Normalization לאחר כל שכבת קונבולוציה כדי לסייע ללמידה יציבה יותר\n",
    "# הגדלת מספר הנוירונים בשכבות ה-FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f84f4fbb-2745-41c7-90fa-40638a82946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=196):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)  # הוספת נורמליזציה\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 14 * 14, 2048)  # הגדלת מספר הנוירונים\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.fc3 = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f76907bf-f7c5-4a50-8fee-d106f0c5dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# יצירת המודל\n",
    "model = CNNClassifier(num_classes=196).to(device)\n",
    "\n",
    "# הגדרת פונקציית הפסד ואופטימיזציה\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "###############################\n",
    "# ניסיון 2 \n",
    "###############################\n",
    "# הגדרת פונקציית הפסד ואופטימיזציה\n",
    "num_epochs = 100  # הגדלת מספר האפוקים\n",
    "\n",
    "criterion = FocalLoss()  # שימוש ב-Focal Loss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-4)  # שינוי מ-SGD ל-AdamW\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # הפחתת הלמידה כל 5 אפוקים\n",
    "# שימוש ב- OneCycleLR במקום StepLR, כך שהמודל יתאים את הלמידה לאורך הזמן\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.005, steps_per_epoch=len(train_loader), epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adb350f1-e3f5-46f5-ba7d-fd681841ebd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()  # אם יש GPU \n",
    "gc.collect()  # ניקוי זיכרון בפייתון\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0c0016b-1538-4793-8a67-bcba5ba54043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# פונקציות אימון ובדיקה\n",
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    running_loss = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()  # עדכון הלרנינג רייט בסוף כל אפוק\n",
    "    end_time = time.time()\n",
    "    running_loss /= len(train_loader)\n",
    "    return running_loss, end_time - start_time\n",
    "    \n",
    "\n",
    "# פונקציה לבדיקה של המודל\n",
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        running_loss = 0\n",
    "        total_predictions = 0\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "        \n",
    "        running_loss /= len(test_loader)\n",
    "        accuracy = (correct_predictions / total_predictions)*100.0\n",
    "        return running_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77e23818-c0e7-4cb4-a186-c08362ed4ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# שילוב Early Stopping \n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a701e453-541e-406c-8e1f-4c51b35e48c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.001):\n",
    "        \"\"\"\n",
    "        patience - מספר האפוקים ללא שיפור לפני עצירה\n",
    "        min_delta - השיפור המינימלי שייחשב לשיפור אמיתי\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0  # אפס את הספירה אם יש שיפור\n",
    "        else:\n",
    "            self.counter += 1  # ספירה של אפוקים ללא שיפור\n",
    "\n",
    "        return self.counter >= self.patience  # עצור אם חרגנו ממספר האפוקים המותר\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e39eb27f-9b2e-4568-8a4f-ad3a919774ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: Train Loss = 1.374529, Time = 1139.93s\n",
      "Test Loss = 1.295340, Accuracy = 0.73%\n",
      "------------------------------------------------------------\n",
      "Epoch 2/100: Train Loss = 1.297527, Time = 1119.25s\n",
      "Test Loss = 1.285119, Accuracy = 1.24%\n",
      "------------------------------------------------------------\n",
      "Epoch 3/100: Train Loss = 1.292648, Time = 1118.49s\n",
      "Test Loss = 1.285031, Accuracy = 1.32%\n",
      "------------------------------------------------------------\n",
      "Epoch 4/100: Train Loss = 1.288354, Time = 1137.09s\n",
      "Test Loss = 1.281362, Accuracy = 1.16%\n",
      "------------------------------------------------------------\n",
      "Epoch 5/100: Train Loss = 1.285364, Time = 1137.85s\n",
      "Test Loss = 1.282062, Accuracy = 1.75%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m  \u001b[38;5;66;03m# הגדלת מספר האפוקים\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 7\u001b[0m     train_loss, train_time \u001b[38;5;241m=\u001b[39m train_epoch(model, train_loader, criterion, optimizer)\n\u001b[0;32m      8\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m test_model(model, test_loader, criterion)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Train Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Time = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[17], line 18\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[0;32m     15\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 18\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     20\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# עדכון הלרנינג רייט בסוף כל אפוק\u001b[39;00m\n\u001b[0;32m     21\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# אימון הרשת\n",
    "early_stopping = EarlyStopping(patience=10, min_delta=0.001)  # עצירה אחרי 10 אפוקים ללא שיפור\n",
    "\n",
    "num_epochs = 100  # הגדלת מספר האפוקים\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_time = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    test_loss, test_acc = test_model(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss = {train_loss:.6f}, Time = {train_time:.2f}s\")\n",
    "    print(f\"Test Loss = {test_loss:.6f}, Accuracy = {test_acc:.2f}%\")\n",
    "    print('-' * 60)\n",
    "\n",
    "    if early_stopping(test_loss):  # בדיקה אם צריך לעצור\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "\n",
    "# שמירת המודל\n",
    "torch.save(model.state_dict(), \"cars196_cnn_trained.pth\")\n",
    "print(\"End-to-End CNN model training completed and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e1d6b5-1b06-45d1-8943-670559d180c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
