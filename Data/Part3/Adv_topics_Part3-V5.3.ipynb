{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5ab4caa-bdeb-4b2e-9c86-249051a669a9",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(17, 116, 155);text-align:left;font-size:250%;font-family:verdana;text-decoration:underline;\"> \n",
    "    Advanced topics - Final Project - Part 3: End-to-End CNN</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db3e8b2-a92b-49fa-aab6-e10dc30d9bd7",
   "metadata": {},
   "source": [
    "### <u>שיפור ארכיטקטורת הרשת ומניעת Overfitting – Dropout והפחתת כמות הפיצ'רים בשכבות הצפופות</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8cc0cd-f383-4cd0-bc2e-3285c12b2661",
   "metadata": {},
   "source": [
    "## <u>Imports</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68399c62-7323-4d76-8ce9-e0b83824a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24211b00-91e2-4d41-83b9-3a35b28efd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# קביעת התקן (GPU אם קיים)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8003671-a3d3-4e86-bf59-d1cac45c8f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()  # אם יש GPU \n",
    "gc.collect()  # ניקוי זיכרון בפייתון"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ea9bea-8f37-4824-b77c-f54ed44d9947",
   "metadata": {},
   "source": [
    "## <u>Load and Preprocess Dataset</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28b29a1c-dc42-4ed5-9b93-bb9426860437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Cars196 dataset from TFRecord files...\n",
      "Loaded 8144 training images and 8041 test images.\n"
     ]
    }
   ],
   "source": [
    "# טעינת הנתונים (TFRecord) והכנה לפורמט PyTorch\n",
    "print(\"Loading Cars196 dataset from TFRecord files...\")\n",
    "\n",
    "data_dir = r\"C:\\Users\\yifat\\Data Science\\נושאים מתקדמים\\Final_Project_Shay\\cars196\"\n",
    "\n",
    "# יצירת רשימת קבצי ה-TFRecord\n",
    "train_files = [os.path.join(data_dir, f\"cars196-train.tfrecord-0000{i}-of-00008\") for i in range(8)]\n",
    "test_files = [os.path.join(data_dir, f\"cars196-test.tfrecord-0000{i}-of-00008\") for i in range(8)]\n",
    "\n",
    "# פונקציה לקריאת TFRecord\n",
    "def parse_tfrecord(example):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    parsed_example = tf.io.parse_single_example(example, feature_description)\n",
    "    \n",
    "    image = tf.image.decode_jpeg(parsed_example['image'], channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)  # מונע איבוד מידע\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "\n",
    "    label = parsed_example['label']\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def load_tfrecord_dataset(filenames):\n",
    "    raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = raw_dataset.map(parse_tfrecord)\n",
    "    return list(dataset)  # ממירים לרשימה לשימוש ב-PyTorch\n",
    "\n",
    "# טעינת ה-Train/Test מ-TFRecord\n",
    "train_data = [(image, label) for image, label in load_tfrecord_dataset(train_files)]\n",
    "test_data = [(image, label) for image, label in load_tfrecord_dataset(test_files)]\n",
    "\n",
    "print(f\"Loaded {len(train_data)} training images and {len(test_data)} test images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43222f66-5890-4225-b2c2-acce6487b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ביצוע דגימה אקראית מכל מחלקה ע\"מ ליצור כמות דאטה קטנה יותר לצורכי בדיקת המודל והרצות מהירות יותר\n",
    "# הדגימה תעשה ע\"י ייצוג שיוויוני מכל מחלקה קיימת בדאטה-סט, כדי לוודא שכל הקטגוריות מיוצגות\n",
    "# לצורך כך, אבחר 10% מהתמונות של כל מחלקה בנפרד, כדי שכל המחלקות יופיעו"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0a1a634-8620-44c0-8260-080881b11b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 734 training images and 727 test images from all classes.\n"
     ]
    }
   ],
   "source": [
    "# קביעת אחוז הדאטה לשימוש\n",
    "subset_ratio = 0.1  # 10% מכל מחלקה\n",
    "\n",
    "# ארגון הדאטה לפי מחלקות\n",
    "class_to_images = defaultdict(list)\n",
    "for image, label in train_data:\n",
    "    class_to_images[label.numpy()].append((image, label))\n",
    "\n",
    "# בחירת 10% מכל מחלקה\n",
    "filtered_train_data = []\n",
    "for label, images in class_to_images.items():\n",
    "    num_samples = max(1, int(len(images) * subset_ratio))  # לוודא שיש לפחות תמונה אחת\n",
    "    filtered_train_data.extend(random.sample(images, num_samples))\n",
    "\n",
    "# חזרה על זה עבור הדאטה של הבדיקות\n",
    "class_to_images_test = defaultdict(list)\n",
    "for image, label in test_data:\n",
    "    class_to_images_test[label.numpy()].append((image, label))\n",
    "\n",
    "filtered_test_data = []\n",
    "for label, images in class_to_images_test.items():\n",
    "    num_samples = max(1, int(len(images) * subset_ratio))\n",
    "    filtered_test_data.extend(random.sample(images, num_samples))\n",
    "\n",
    "# עדכון הדאטה\n",
    "train_data = filtered_train_data\n",
    "test_data = filtered_test_data\n",
    "\n",
    "print(f\"Using {len(train_data)} training images and {len(test_data)} test images from all classes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00fbc8aa-92ef-447d-af0d-b1312d8d9292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# מחלקת Dataset לטעינת הנתונים\n",
    "class Cars196Dataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_tf, label = self.data[idx]  # image_tf הוא Tensor של TensorFlow\n",
    "        image_np = image_tf.numpy()  # המרה ל-NumPy\n",
    "        image = Image.fromarray((image_np * 255).astype(np.uint8))  # הבאת הפיקסלים לטווח 0-255\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label.numpy()  # גם label צריך להיות מספר ולא Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c06a716-0100-4db0-baea-1457b189d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ניסיון עם אוגמנטציה פחות אגרסיבית\n",
    "# הפחתת רמת ה-ColorJitter והאוגמנטציות הגורמות לעיוותים גדולים כמו RandomPerspective ו-RandomAffine\n",
    "# הימנעות מיותר מדי RandomErasing, שכן זה יכול לגרום לאיבוד מידע חשוב\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb725ff1-c3d5-464a-9cab-0c439329eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # היפוך אופקי\n",
    "    transforms.RandomRotation(10),  # הקטנת סיבוב ל-10 מעלות\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),  # הקטנת שינויי הצבעים\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # פחות חיתוך\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# סט הבדיקה ללא אוגמנטציה\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28dbf99e-0ea1-4878-a1da-49acb5dfffe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test Dataloaders created with batch size 32.\n",
      "Training samples: 734, Testing samples: 727\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_dataset = Cars196Dataset(train_data, transform=train_transform)\n",
    "test_dataset = Cars196Dataset(test_data, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Train and Test Dataloaders created with batch size {batch_size}.\")\n",
    "print(f\"Training samples: {len(train_dataset)}, Testing samples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18506724-355b-44d8-bbeb-2a1a0482e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# חישוב משקלים למחלקות לטיפול בחוסר איזון\n",
    "labels_list = np.array([label.numpy() for _, label in train_data])  # המרה ל-NumPy\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels_list), y=labels_list)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)  # המרה ל-Tensor של PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad66359-9706-4558-9b71-27eac9627f6f",
   "metadata": {},
   "source": [
    "## <u>Define and Train a CNN Model</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7253cfb6-86c3-4848-8087-ccf6b37ed0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# שיפור ארכיטקטורת הרשת – הוספת שכבות, נרמול ושכבות קונבולוציה נוספות\n",
    "#######################################################\n",
    "# הוספת שכבות Batch Normalization תייצב את הלמידה ותאפשר התכנסות טובה יותר.\n",
    "# הוספת Conv+MaxPooling כפולות יאפשרו למודל ללמוד יותר פרמטרים תוך שמירה על יעילות חישובית.\n",
    "# מניעת Overfitting – Dropout והפחתת כמות הפיצ'רים בשכבות הצפופות\n",
    "#########################################################\n",
    "# הוספת Dropout בשכבות הסופיות תמנע מהמודל לזכור דוגמאות במקום ללמוד מהן.\n",
    "# הפחתת כמות הנוירונים מקטינה למודל את המורכבות."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f84f4fbb-2745-41c7-90fa-40638a82946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=196):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.conv5 = nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1)  # שכבה נוספת\n",
    "        self.bn5 = nn.BatchNorm2d(1024)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.dropout = nn.Dropout(0.6)  # העלאת dropout ל-0.6\n",
    "\n",
    "        # הפחתת כמות הפיצ'רים בשכבות הצפופות\n",
    "        self.fc1 = nn.Linear(1024 * 7 * 7, 1024)  \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = self.pool(F.relu(self.bn5(self.conv5(x))))  # שכבה נוספת\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed3ff931-ddb5-4a13-aa8a-ed4c104c4a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is running on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# יצירת המודל\n",
    "model = CNNClassifier(num_classes=196).to(device)\n",
    "\n",
    "# בדיקה האם המודל נטען ל-GPU או לא\n",
    "print(f\"Model is running on: {next(model.parameters()).device}\")\n",
    "\n",
    "# הגדרת פונקציית הפסד ואופטימיזציה\n",
    "num_epochs = 50  # הגדלת מספר האפוקים\n",
    "\n",
    "# פונקציית הפסד: שימוש בשקלול מחלקות בלבד\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-4)  # שינוי מ-SGD ל-AdamW\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.005, steps_per_epoch=len(train_loader), epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcf7f4e1-75d0-4b35-b5e2-564dcdcb4f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # צריך להחזיר True\n",
    "print(torch.cuda.device_count())  # צריך להיות 1 לפחות\n",
    "print(torch.cuda.get_device_name(0))  # שם הכרטיס הגרפי\n",
    "\n",
    "torch.cuda.empty_cache()  # אם יש GPU \n",
    "gc.collect()  # ניקוי זיכרון בפייתון"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0c0016b-1538-4793-8a67-bcba5ba54043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# פונקציות אימון ובדיקה\n",
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    running_loss = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()  # עדכון הלרנינג רייט בסוף כל אפוק\n",
    "    end_time = time.time()\n",
    "    running_loss /= len(train_loader)\n",
    "    return running_loss, end_time - start_time\n",
    "    \n",
    "\n",
    "# פונקציה לבדיקה של המודל\n",
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        running_loss = 0\n",
    "        total_predictions = 0\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "        \n",
    "        running_loss /= len(test_loader)\n",
    "        accuracy = (correct_predictions / total_predictions)*100.0\n",
    "        return running_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77e23818-c0e7-4cb4-a186-c08362ed4ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# שילוב Early Stopping \n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a701e453-541e-406c-8e1f-4c51b35e48c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.001):\n",
    "        \"\"\"\n",
    "        patience - מספר האפוקים ללא שיפור לפני עצירה\n",
    "        min_delta - השיפור המינימלי שייחשב לשיפור אמיתי\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0  # אפס את הספירה אם יש שיפור\n",
    "        else:\n",
    "            self.counter += 1  # ספירה של אפוקים ללא שיפור\n",
    "\n",
    "        return self.counter >= self.patience  # עצור אם חרגנו ממספר האפוקים המותר\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e39eb27f-9b2e-4568-8a4f-ad3a919774ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: Train Loss = 6.180623, Time = 104.86s\n",
      "Test Loss = 5.396868, Accuracy = 0.41%\n",
      "------------------------------------------------------------\n",
      "Epoch 2/50: Train Loss = 5.524428, Time = 102.91s\n",
      "Test Loss = 5.349224, Accuracy = 0.14%\n",
      "------------------------------------------------------------\n",
      "Epoch 3/50: Train Loss = 5.366654, Time = 103.06s\n",
      "Test Loss = 5.286733, Accuracy = 0.69%\n",
      "------------------------------------------------------------\n",
      "Epoch 4/50: Train Loss = 5.275252, Time = 102.91s\n",
      "Test Loss = 5.278483, Accuracy = 0.41%\n",
      "------------------------------------------------------------\n",
      "Epoch 5/50: Train Loss = 5.230453, Time = 102.72s\n",
      "Test Loss = 5.271649, Accuracy = 0.55%\n",
      "------------------------------------------------------------\n",
      "Epoch 6/50: Train Loss = 5.219839, Time = 102.85s\n",
      "Test Loss = 5.285413, Accuracy = 0.96%\n",
      "------------------------------------------------------------\n",
      "Epoch 7/50: Train Loss = 5.206779, Time = 102.78s\n",
      "Test Loss = 5.271497, Accuracy = 0.55%\n",
      "------------------------------------------------------------\n",
      "Epoch 8/50: Train Loss = 5.182988, Time = 102.93s\n",
      "Test Loss = 5.257724, Accuracy = 0.83%\n",
      "------------------------------------------------------------\n",
      "Epoch 9/50: Train Loss = 5.169992, Time = 102.87s\n",
      "Test Loss = 5.257280, Accuracy = 1.24%\n",
      "------------------------------------------------------------\n",
      "Epoch 10/50: Train Loss = 5.165054, Time = 102.76s\n",
      "Test Loss = 5.266669, Accuracy = 1.24%\n",
      "------------------------------------------------------------\n",
      "Epoch 11/50: Train Loss = 5.120411, Time = 102.81s\n",
      "Test Loss = 5.269118, Accuracy = 1.51%\n",
      "------------------------------------------------------------\n",
      "Epoch 12/50: Train Loss = 5.133610, Time = 103.11s\n",
      "Test Loss = 5.253508, Accuracy = 1.38%\n",
      "------------------------------------------------------------\n",
      "Epoch 13/50: Train Loss = 5.106621, Time = 103.74s\n",
      "Test Loss = 5.252004, Accuracy = 0.83%\n",
      "------------------------------------------------------------\n",
      "Epoch 14/50: Train Loss = 5.069303, Time = 102.85s\n",
      "Test Loss = 5.268379, Accuracy = 0.96%\n",
      "------------------------------------------------------------\n",
      "Epoch 15/50: Train Loss = 5.072981, Time = 102.88s\n",
      "Test Loss = 5.289897, Accuracy = 0.83%\n",
      "------------------------------------------------------------\n",
      "Epoch 16/50: Train Loss = 5.051707, Time = 102.90s\n",
      "Test Loss = 5.284545, Accuracy = 0.83%\n",
      "------------------------------------------------------------\n",
      "Epoch 17/50: Train Loss = 5.022038, Time = 102.70s\n",
      "Test Loss = 5.316355, Accuracy = 0.55%\n",
      "------------------------------------------------------------\n",
      "Epoch 18/50: Train Loss = 4.973644, Time = 102.74s\n",
      "Test Loss = 5.277417, Accuracy = 0.83%\n",
      "------------------------------------------------------------\n",
      "Epoch 19/50: Train Loss = 4.950245, Time = 102.83s\n",
      "Test Loss = 5.281434, Accuracy = 1.65%\n",
      "------------------------------------------------------------\n",
      "Epoch 20/50: Train Loss = 4.946056, Time = 102.77s\n",
      "Test Loss = 5.374556, Accuracy = 0.55%\n",
      "------------------------------------------------------------\n",
      "Epoch 21/50: Train Loss = 4.880132, Time = 102.70s\n",
      "Test Loss = 5.317806, Accuracy = 0.55%\n",
      "------------------------------------------------------------\n",
      "Epoch 22/50: Train Loss = 4.908910, Time = 102.94s\n",
      "Test Loss = 5.360184, Accuracy = 0.41%\n",
      "------------------------------------------------------------\n",
      "Epoch 23/50: Train Loss = 4.867955, Time = 102.68s\n",
      "Test Loss = 5.346771, Accuracy = 0.55%\n",
      "------------------------------------------------------------\n",
      "Early stopping at epoch 23\n",
      "End-to-End CNN model training completed and saved!\n",
      "Model deleted and GPU memory cleared.\n"
     ]
    }
   ],
   "source": [
    "# אימון הרשת\n",
    "early_stopping = EarlyStopping(patience=10, min_delta=0.001)  # עצירה אחרי 10 אפוקים ללא שיפור\n",
    "\n",
    "num_epochs = 50  # הגדלת מספר האפוקים\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_time = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    test_loss, test_acc = test_model(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss = {train_loss:.6f}, Time = {train_time:.2f}s\")\n",
    "    print(f\"Test Loss = {test_loss:.6f}, Accuracy = {test_acc:.2f}%\")\n",
    "    print('-' * 60)\n",
    "\n",
    "    if early_stopping(test_loss):  # בדיקה אם צריך לעצור\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "\n",
    "# שמירת המודל\n",
    "torch.save(model.state_dict(), \"cars196_cnn_trained.pth\")\n",
    "print(\"End-to-End CNN model training completed and saved!\")\n",
    "\n",
    "# ניקוי מהזיכרון\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(\"Model deleted and GPU memory cleared.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0aa0c244-88f1-4027-9c39-73bb8e974c6c",
   "metadata": {},
   "source": [
    "הפחתת מספר הנוירונים ב-FC מ-2048→1024→512\n",
    "העלנו Dropout מ-0.5 ל-0.6\n",
    "מדד\tלפני השינוי\tאחרי השינוי\n",
    "Train Loss\tירד ל־4.15\tירד עד ~4.87 בלבד\n",
    "Test Accuracy\tעד ~1.9%\tלא עבר 1.65%, רוב הזמן סביב 0.5%-1%\n",
    "Early stopping\tאפוק 15-16\tאפוק 23, כלומר למידה ממושכת יותר – אך לא משתפרת\n",
    "מה זה אומר:\n",
    "המודל לא לומד טוב יותר עם הפיצ'רים המופחתים – להפך, נראה שהוא לומד פחות טוב.\n",
    "Dropout מוגבר פוגע בלמידה בשלב הזה – כנראה שהוא מונע מהמוח הסינתטי ללמוד תבניות חזקות כשהדאטה ממילא קטן ומאתגר.\n",
    "אין שיפור ב-overfitting כי ממילא לא הייתה למידה מספקת שתצדיק רגולריזציה."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
