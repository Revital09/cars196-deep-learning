{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5ab4caa-bdeb-4b2e-9c86-249051a669a9",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(17, 116, 155);text-align:left;font-size:250%;font-family:verdana;text-decoration:underline;\"> \n",
    "    Advanced topics - Final Project - Part 3: End-to-End CNN</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca28128-583b-4897-afcf-435cf65e74a4",
   "metadata": {},
   "source": [
    "## <u>אופטימזציה: SGD, אוגמנטציה משופרת</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8cc0cd-f383-4cd0-bc2e-3285c12b2661",
   "metadata": {},
   "source": [
    "## <u>Imports</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68399c62-7323-4d76-8ce9-e0b83824a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24211b00-91e2-4d41-83b9-3a35b28efd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# קביעת התקן (GPU אם קיים)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ea9bea-8f37-4824-b77c-f54ed44d9947",
   "metadata": {},
   "source": [
    "## <u>Load and Preprocess Dataset</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28b29a1c-dc42-4ed5-9b93-bb9426860437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Cars196 dataset from TFRecord files...\n",
      "Loaded 8144 training images and 8041 test images.\n"
     ]
    }
   ],
   "source": [
    "# שלב 1: טעינת הנתונים (TFRecord) והכנה לפורמט PyTorch\n",
    "print(\"Loading Cars196 dataset from TFRecord files...\")\n",
    "\n",
    "data_dir = r\"C:\\Users\\yifat\\Data Science\\נושאים מתקדמים\\Final_Project_Shay\\cars196\"\n",
    "\n",
    "# יצירת רשימת קבצי ה-TFRecord\n",
    "train_files = [os.path.join(data_dir, f\"cars196-train.tfrecord-0000{i}-of-00008\") for i in range(8)]\n",
    "test_files = [os.path.join(data_dir, f\"cars196-test.tfrecord-0000{i}-of-00008\") for i in range(8)]\n",
    "\n",
    "# פונקציה לקריאת TFRecord\n",
    "def parse_tfrecord(example):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    parsed_example = tf.io.parse_single_example(example, feature_description)\n",
    "    image = tf.image.decode_jpeg(parsed_example['image'], channels=3)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    label = parsed_example['label']\n",
    "    return image, label\n",
    "\n",
    "def load_tfrecord_dataset(filenames):\n",
    "    raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = raw_dataset.map(parse_tfrecord)\n",
    "    return list(dataset)  # ממירים לרשימה לשימוש ב-PyTorch\n",
    "\n",
    "# טעינת ה-Train/Test מ-TFRecord\n",
    "train_data = [(image.numpy().astype('uint8'), label.numpy()) for image, label in load_tfrecord_dataset(train_files)]\n",
    "test_data = [(image.numpy().astype('uint8'), label.numpy()) for image, label in load_tfrecord_dataset(test_files)]\n",
    "\n",
    "print(f\"Loaded {len(train_data)} training images and {len(test_data)} test images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fbc8aa-92ef-447d-af0d-b1312d8d9292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# מחלקת Dataset לטעינת הנתונים\n",
    "class Cars196Dataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_np, label = self.data[idx]\n",
    "        image = Image.fromarray(image_np)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb725ff1-c3d5-464a-9cab-0c439329eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **אוגמנטציה משופרת עבור סט האימון**\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # היפוך אופקי\n",
    "    transforms.RandomRotation(15),  # סיבוב עד 15 מעלות\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),  # שינוי צבעים\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # תזוזה אקראית\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),  # שינוי פרספקטיבה\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # חיתוך עם שינוי קנה מידה\n",
    "    transforms.GaussianBlur(kernel_size=(5, 5)),  # טשטוש אקראי\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# סט הבדיקה ללא אוגמנטציה\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28dbf99e-0ea1-4878-a1da-49acb5dfffe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test Dataloaders created with batch size 32.\n",
      "Training samples: 8144, Testing samples: 8041\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_dataset = Cars196Dataset(train_data, transform=train_transform)\n",
    "test_dataset = Cars196Dataset(test_data, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Train and Test Dataloaders created with batch size {batch_size}.\")\n",
    "print(f\"Training samples: {len(train_dataset)}, Testing samples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad66359-9706-4558-9b71-27eac9627f6f",
   "metadata": {},
   "source": [
    "## <u>Define and Train a CNN Model</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f84f4fbb-2745-41c7-90fa-40638a82946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a CNN model for image classification\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=196):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 14 * 14, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f76907bf-f7c5-4a50-8fee-d106f0c5dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# יצירת המודל\n",
    "model = CNNClassifier(num_classes=196).to(device)\n",
    "\n",
    "# הגדרת פונקציית הפסד ואופטימיזציה\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adb350f1-e3f5-46f5-ba7d-fd681841ebd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()  # אם יש GPU \n",
    "gc.collect()  # ניקוי זיכרון בפייתון\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0c0016b-1538-4793-8a67-bcba5ba54043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# פונקציות אימון ובדיקה\n",
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    running_loss = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    running_loss /= len(train_loader)\n",
    "    return running_loss, end_time - start_time\n",
    "\n",
    "# פונקציה לבדיקה של המודל\n",
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        running_loss = 0\n",
    "        total_predictions = 0\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "        \n",
    "        running_loss /= len(test_loader)\n",
    "        accuracy = (correct_predictions / total_predictions) * 100.0\n",
    "        return running_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c554516a-2473-4d0c-b418-5bb19519fecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({118: 68, 78: 49, 160: 48, 166: 48, 55: 47, 143: 47, 190: 46, 161: 46, 193: 46, 181: 46, 94: 46, 97: 46, 42: 46, 19: 46, 170: 46, 111: 46, 106: 45, 146: 45, 5: 45, 33: 45, 0: 45, 120: 45, 23: 45, 43: 45, 52: 45, 80: 45, 122: 45, 7: 45, 152: 45, 114: 45, 113: 45, 72: 45, 178: 45, 58: 45, 81: 45, 71: 45, 108: 45, 64: 45, 164: 45, 147: 45, 124: 44, 171: 44, 163: 44, 144: 44, 86: 44, 93: 44, 73: 44, 131: 44, 150: 44, 107: 44, 62: 44, 15: 44, 136: 44, 169: 44, 176: 44, 75: 44, 187: 44, 172: 44, 88: 44, 30: 44, 84: 44, 74: 44, 45: 44, 186: 44, 159: 44, 104: 44, 57: 44, 194: 43, 2: 43, 50: 43, 145: 43, 69: 43, 13: 43, 119: 43, 153: 43, 17: 43, 112: 43, 179: 43, 14: 43, 154: 43, 60: 43, 85: 43, 79: 43, 191: 43, 103: 43, 47: 43, 138: 43, 116: 43, 189: 43, 148: 43, 28: 43, 109: 43, 21: 43, 182: 42, 130: 42, 83: 42, 20: 42, 3: 42, 100: 42, 105: 42, 31: 42, 117: 42, 96: 42, 32: 42, 125: 42, 49: 42, 177: 42, 139: 42, 167: 42, 65: 42, 192: 42, 134: 42, 132: 42, 29: 42, 110: 42, 18: 41, 89: 41, 16: 41, 51: 41, 129: 41, 95: 41, 165: 41, 126: 41, 183: 41, 12: 41, 76: 41, 37: 41, 34: 41, 82: 41, 8: 41, 35: 41, 173: 41, 4: 41, 27: 41, 188: 41, 91: 40, 137: 40, 142: 40, 121: 40, 24: 40, 53: 40, 195: 40, 87: 40, 54: 40, 102: 40, 22: 40, 67: 40, 39: 39, 36: 39, 123: 39, 175: 39, 168: 39, 92: 39, 127: 39, 185: 39, 90: 39, 6: 39, 155: 39, 66: 39, 101: 39, 184: 39, 128: 39, 68: 38, 56: 38, 77: 38, 48: 38, 180: 38, 10: 38, 115: 38, 11: 37, 156: 37, 59: 37, 38: 37, 61: 37, 162: 37, 26: 36, 149: 36, 151: 36, 40: 36, 158: 36, 46: 35, 41: 35, 70: 35, 140: 34, 99: 34, 25: 34, 133: 34, 44: 33, 9: 33, 141: 33, 1: 32, 174: 31, 63: 30, 157: 29, 98: 28, 135: 24})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "labels_count = collections.Counter([label for _, label in train_data])\n",
    "print(labels_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39eb27f-9b2e-4568-8a4f-ad3a919774ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: Train Loss = 5.279534, Time = 153.27s\n",
      "Test Loss = 5.277839, Accuracy = 0.53%\n",
      "Epoch 2/20: Train Loss = 5.278195, Time = 148.84s\n",
      "Test Loss = 5.277124, Accuracy = 0.53%\n",
      "Epoch 3/20: Train Loss = 5.278186, Time = 146.58s\n",
      "Test Loss = 5.276682, Accuracy = 0.71%\n",
      "Epoch 4/20: Train Loss = 5.277505, Time = 146.84s\n",
      "Test Loss = 5.276024, Accuracy = 0.85%\n",
      "Epoch 5/20: Train Loss = 5.277150, Time = 145.14s\n",
      "Test Loss = 5.275410, Accuracy = 0.85%\n",
      "Epoch 6/20: Train Loss = 5.275642, Time = 144.90s\n",
      "Test Loss = 5.274494, Accuracy = 0.85%\n",
      "Epoch 7/20: Train Loss = 5.275830, Time = 153.13s\n",
      "Test Loss = 5.273646, Accuracy = 0.85%\n",
      "Epoch 8/20: Train Loss = 5.275751, Time = 152.63s\n",
      "Test Loss = 5.272994, Accuracy = 0.85%\n",
      "Epoch 9/20: Train Loss = 5.274849, Time = 153.74s\n",
      "Test Loss = 5.272412, Accuracy = 0.85%\n",
      "Epoch 10/20: Train Loss = 5.274338, Time = 151.70s\n",
      "Test Loss = 5.271716, Accuracy = 0.85%\n",
      "Epoch 11/20: Train Loss = 5.273350, Time = 152.70s\n",
      "Test Loss = 5.270616, Accuracy = 0.85%\n",
      "Epoch 12/20: Train Loss = 5.273355, Time = 151.67s\n",
      "Test Loss = 5.270010, Accuracy = 0.85%\n"
     ]
    }
   ],
   "source": [
    "# אימון הרשת\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_time = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    test_loss, test_acc = test_model(model, test_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss = {train_loss:.6f}, Time = {train_time:.2f}s\")\n",
    "    print(f\"Test Loss = {test_loss:.6f}, Accuracy = {test_acc:.2f}%\")\n",
    "\n",
    "# שמירת המודל\n",
    "torch.save(model.state_dict(), \"cars196_cnn_trained.pth\")\n",
    "print(\"End-to-End CNN model training completed and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e1d6b5-1b06-45d1-8943-670559d180c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
