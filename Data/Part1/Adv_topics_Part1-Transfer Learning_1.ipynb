{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23dba62d-7ebf-44d0-86b2-0e74283f27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "# Import required libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchinfo\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01059efa-5ee7-45b1-9b28-f16978a4225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarsDataset(Dataset):\n",
    "    def __init__(self, annotations, img_dir, transform=None):\n",
    "        self.img_paths = [os.path.join(img_dir, sample[-1][0]) for sample in annotations[0]]\n",
    "        self.labels = [sample[-2][0][0] - 1 for sample in annotations[0]]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.img_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "cars_dataset = torch.load(\"cars196_dataset.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb9c8cf-a2c2-4bbf-87d3-aa7060689eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "מספר דוגמאות בדאטהסט: 16185\n"
     ]
    }
   ],
   "source": [
    "# הצגת גודל הדאטהסט\n",
    "print(f\"מספר דוגמאות בדאטהסט: {len(cars_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c1d6878-0eda-4dcd-bc78-4838c9a864bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # הופכים תמונה אופקית באופן אקראי\n",
    "    transforms.RandomRotation(15),  # מסובבים מעט את התמונה כדי להוסיף גיוון\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # התאמות צבע\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# עבור בדיקות - לא צריך אוגמנטציה\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffadf586-ec92-4a22-92ea-990fb57e4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "# חלוקת הדאטה לאימון ולמבחן\n",
    "dataset_size = len(cars_dataset)\n",
    "train_size = int(0.7 * dataset_size)  # 70% מהדאטה\n",
    "test_size = dataset_size - train_size  # 30% הנותרים\n",
    "\n",
    "train_indices, test_indices = train_test_split(range(dataset_size), train_size=train_size, test_size=test_size, random_state=42)\n",
    "\n",
    "train_dataset = Subset(cars_dataset, train_indices)\n",
    "test_dataset = Subset(cars_dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c5bded3-e399-4932-8c9b-b64048b2ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# יצירת DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f68fd0c0-b3c6-404a-9e5c-3cfdae0e5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import MobileNet_V2_Weights\n",
    "\n",
    "base_model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d1bd3df-a17d-4320-8bb6-042996e1a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMobileNet(nn.Module):\n",
    "    def __init__(self, base_model, num_classes=196):\n",
    "        super(CustomMobileNet, self).__init__()\n",
    "        self.base = base_model.features  # שמירה על כל השכבות של MobileNetV2\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)  # pooling\n",
    "        self.dropout = nn.Dropout(0.5)  # הוסף שכבת Dropout\n",
    "        self.fc = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten לפני fully connected layers\n",
    "        x = self.dropout(x)  # Dropout לפני השכבה הסופית\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# יצירת המודל עם 196 מחלקות\n",
    "model = CustomMobileNet(base_model, num_classes=196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32f65bc7-aa40-4868-8de0-844eeb28394d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomMobileNet(\n",
       "  (base): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=1280, out_features=196, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b988e316-1418-4a10-84a6-45ee1483d0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 196])\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 3, 224, 224)  # תמונה מדומה\n",
    "output = model(dummy_input)\n",
    "print(\"Output shape:\", output.shape)  # צריך להיות torch.Size([1, 196])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1370c3f7-7ca7-4227-b4b3-32f4379becf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================================================================================================\n",
       "Layer (type:depth-idx)                             Input Shape               Output Shape              Param #                   Trainable\n",
       "======================================================================================================================================================\n",
       "CustomMobileNet                                    [1, 3, 224, 224]          [1, 196]                  --                        True\n",
       "├─Sequential: 1-1                                  [1, 3, 224, 224]          [1, 1280, 7, 7]           --                        True\n",
       "│    └─Conv2dNormActivation: 2-1                   [1, 3, 224, 224]          [1, 32, 112, 112]         --                        True\n",
       "│    │    └─Conv2d: 3-1                            [1, 3, 224, 224]          [1, 32, 112, 112]         864                       True\n",
       "│    │    └─BatchNorm2d: 3-2                       [1, 32, 112, 112]         [1, 32, 112, 112]         64                        True\n",
       "│    │    └─ReLU6: 3-3                             [1, 32, 112, 112]         [1, 32, 112, 112]         --                        --\n",
       "│    └─InvertedResidual: 2-2                       [1, 32, 112, 112]         [1, 16, 112, 112]         --                        True\n",
       "│    │    └─Sequential: 3-4                        [1, 32, 112, 112]         [1, 16, 112, 112]         896                       True\n",
       "│    └─InvertedResidual: 2-3                       [1, 16, 112, 112]         [1, 24, 56, 56]           --                        True\n",
       "│    │    └─Sequential: 3-5                        [1, 16, 112, 112]         [1, 24, 56, 56]           5,136                     True\n",
       "│    └─InvertedResidual: 2-4                       [1, 24, 56, 56]           [1, 24, 56, 56]           --                        True\n",
       "│    │    └─Sequential: 3-6                        [1, 24, 56, 56]           [1, 24, 56, 56]           8,832                     True\n",
       "│    └─InvertedResidual: 2-5                       [1, 24, 56, 56]           [1, 32, 28, 28]           --                        True\n",
       "│    │    └─Sequential: 3-7                        [1, 24, 56, 56]           [1, 32, 28, 28]           10,000                    True\n",
       "│    └─InvertedResidual: 2-6                       [1, 32, 28, 28]           [1, 32, 28, 28]           --                        True\n",
       "│    │    └─Sequential: 3-8                        [1, 32, 28, 28]           [1, 32, 28, 28]           14,848                    True\n",
       "│    └─InvertedResidual: 2-7                       [1, 32, 28, 28]           [1, 32, 28, 28]           --                        True\n",
       "│    │    └─Sequential: 3-9                        [1, 32, 28, 28]           [1, 32, 28, 28]           14,848                    True\n",
       "│    └─InvertedResidual: 2-8                       [1, 32, 28, 28]           [1, 64, 14, 14]           --                        True\n",
       "│    │    └─Sequential: 3-10                       [1, 32, 28, 28]           [1, 64, 14, 14]           21,056                    True\n",
       "│    └─InvertedResidual: 2-9                       [1, 64, 14, 14]           [1, 64, 14, 14]           --                        True\n",
       "│    │    └─Sequential: 3-11                       [1, 64, 14, 14]           [1, 64, 14, 14]           54,272                    True\n",
       "│    └─InvertedResidual: 2-10                      [1, 64, 14, 14]           [1, 64, 14, 14]           --                        True\n",
       "│    │    └─Sequential: 3-12                       [1, 64, 14, 14]           [1, 64, 14, 14]           54,272                    True\n",
       "│    └─InvertedResidual: 2-11                      [1, 64, 14, 14]           [1, 64, 14, 14]           --                        True\n",
       "│    │    └─Sequential: 3-13                       [1, 64, 14, 14]           [1, 64, 14, 14]           54,272                    True\n",
       "│    └─InvertedResidual: 2-12                      [1, 64, 14, 14]           [1, 96, 14, 14]           --                        True\n",
       "│    │    └─Sequential: 3-14                       [1, 64, 14, 14]           [1, 96, 14, 14]           66,624                    True\n",
       "│    └─InvertedResidual: 2-13                      [1, 96, 14, 14]           [1, 96, 14, 14]           --                        True\n",
       "│    │    └─Sequential: 3-15                       [1, 96, 14, 14]           [1, 96, 14, 14]           118,272                   True\n",
       "│    └─InvertedResidual: 2-14                      [1, 96, 14, 14]           [1, 96, 14, 14]           --                        True\n",
       "│    │    └─Sequential: 3-16                       [1, 96, 14, 14]           [1, 96, 14, 14]           118,272                   True\n",
       "│    └─InvertedResidual: 2-15                      [1, 96, 14, 14]           [1, 160, 7, 7]            --                        True\n",
       "│    │    └─Sequential: 3-17                       [1, 96, 14, 14]           [1, 160, 7, 7]            155,264                   True\n",
       "│    └─InvertedResidual: 2-16                      [1, 160, 7, 7]            [1, 160, 7, 7]            --                        True\n",
       "│    │    └─Sequential: 3-18                       [1, 160, 7, 7]            [1, 160, 7, 7]            320,000                   True\n",
       "│    └─InvertedResidual: 2-17                      [1, 160, 7, 7]            [1, 160, 7, 7]            --                        True\n",
       "│    │    └─Sequential: 3-19                       [1, 160, 7, 7]            [1, 160, 7, 7]            320,000                   True\n",
       "│    └─InvertedResidual: 2-18                      [1, 160, 7, 7]            [1, 320, 7, 7]            --                        True\n",
       "│    │    └─Sequential: 3-20                       [1, 160, 7, 7]            [1, 320, 7, 7]            473,920                   True\n",
       "│    └─Conv2dNormActivation: 2-19                  [1, 320, 7, 7]            [1, 1280, 7, 7]           --                        True\n",
       "│    │    └─Conv2d: 3-21                           [1, 320, 7, 7]            [1, 1280, 7, 7]           409,600                   True\n",
       "│    │    └─BatchNorm2d: 3-22                      [1, 1280, 7, 7]           [1, 1280, 7, 7]           2,560                     True\n",
       "│    │    └─ReLU6: 3-23                            [1, 1280, 7, 7]           [1, 1280, 7, 7]           --                        --\n",
       "├─AdaptiveAvgPool2d: 1-2                           [1, 1280, 7, 7]           [1, 1280, 1, 1]           --                        --\n",
       "├─Dropout: 1-3                                     [1, 1280]                 [1, 1280]                 --                        --\n",
       "├─Linear: 1-4                                      [1, 1280]                 [1, 196]                  251,076                   True\n",
       "======================================================================================================================================================\n",
       "Total params: 2,474,948\n",
       "Trainable params: 2,474,948\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 299.78\n",
       "======================================================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 106.85\n",
       "Params size (MB): 9.90\n",
       "Estimated Total Size (MB): 117.35\n",
       "======================================================================================================================================================"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=(1, 3, 224, 224), col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d54cb7fe-d0ff-4ba5-b73c-4014a2c4f645",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # מקפיא את כל השכבות\n",
    "\n",
    "for param in list(model.base.parameters())[-4:]:  \n",
    "    param.requires_grad = True  # פותח 4 השכבות האחרונות לאימון"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5050dd11-95ff-4804-8721-4012a55bb54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader Size: 11329\n",
      "Test Loader Size: 4856\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Loader Size: {len(train_loader.dataset)}\")\n",
    "print(f\"Test Loader Size: {len(test_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5a4928d-dacf-4e42-88de-19a52c6e7063",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0003, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a98d07c2-3bf0-4461-bd71-3ba736606eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, scheduler):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    running_loss = 0\n",
    "    \n",
    "    print(\"Starting Training Epoch...\")  # בדיקה\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(\"cpu\")\n",
    "        target = target.to(\"cpu\").long()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    running_loss /= len(train_loader)\n",
    "    scheduler.step()\n",
    "    \n",
    "    print('Train Loss:', running_loss)\n",
    "    return running_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41ef8e15-6b00-434a-8f90-d6b3057dc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        running_loss = 0\n",
    "        total_predictions = 0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        # CODE HERE\n",
    "        for batch_idx,(data,target) in enumerate(test_loader):\n",
    "            data = data.to(\"cpu\")\n",
    "            target = target.to(\"cpu\").long()\n",
    "            outputs = model(data) #forward step\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted==target).sum().item()\n",
    "            \n",
    "            loss = criterion(outputs,target)#loss\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        running_loss /= len(train_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        print('Test Loss: ',running_loss, ' Accuracy: ', acc,'%')\n",
    "        return running_loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7548e81-d812-456a-9019-f681a5acdc21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Epoch...\n",
      "Train Loss: 4.98505788326936\n",
      "Test Loss:  1.9387338632252724  Accuracy:  16.186161449752884 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 4.3723437019396565\n",
      "Test Loss:  1.7682771887866666  Accuracy:  24.794069192751238 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 4.052766601524837\n",
      "Test Loss:  1.6848998880184587  Accuracy:  29.2833607907743 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.838150596753162\n",
      "Test Loss:  1.6229099474101207  Accuracy:  32.96952224052718 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.676766118814982\n",
      "Test Loss:  1.5718680951423807  Accuracy:  35.09060955518946 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.5241305764202338\n",
      "Test Loss:  1.5600598231693585  Accuracy:  35.99670510708402 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.456685948607279\n",
      "Test Loss:  1.5297714712253243  Accuracy:  36.861614497528834 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.4034935220844824\n",
      "Test Loss:  1.506143156328726  Accuracy:  37.31466227347611 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.346201042866673\n",
      "Test Loss:  1.49481542019649  Accuracy:  38.344316309719936 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.2923835595000446\n",
      "Test Loss:  1.4808633105542999  Accuracy:  38.344316309719936 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.2131361120678643\n",
      "Test Loss:  1.4619225349345564  Accuracy:  39.16803953871499 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.2027136348030294\n",
      "Test Loss:  1.4725087415348155  Accuracy:  39.373970345963755 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.167994994202521\n",
      "Test Loss:  1.4651846485514566  Accuracy:  39.99176276771005 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.1519354879435766\n",
      "Test Loss:  1.4401266843879172  Accuracy:  39.92998352553542 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.1261373998752267\n",
      "Test Loss:  1.443390126288862  Accuracy:  40.58896210873147 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.101175138408946\n",
      "Test Loss:  1.4350661716945416  Accuracy:  40.547775947281714 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.0854145562531077\n",
      "Test Loss:  1.4416618871756097  Accuracy:  40.362438220757824 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.0779621160585218\n",
      "Test Loss:  1.438817081397612  Accuracy:  41.39209225700164 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.064189636152453\n",
      "Test Loss:  1.4305093207715764  Accuracy:  41.28912685337727 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.0551710525588023\n",
      "Test Loss:  1.418118486955909  Accuracy:  41.33031301482702 %\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "Train_loss = []\n",
    "Test_loss = []\n",
    "Test_acc = []\n",
    "\n",
    "try:\n",
    "    for i in range(n_epochs):\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, scheduler)  \n",
    "        test_loss, test_acc = test_model(model, test_loader, criterion)\n",
    "        \n",
    "        Train_loss.append(train_loss)\n",
    "        Test_loss.append(test_loss)\n",
    "        Test_acc.append(test_acc)\n",
    "        \n",
    "        print('*' * 60)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error during training:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c308f8f2-5800-48b3-aab2-4111467964be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18f91435-9d5c-4353-8b5e-8e6ca890ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # מקפיא את כל השכבות\n",
    "\n",
    "for param in list(model.base.parameters())[-8:]:  \n",
    "    param.requires_grad = True  # פותח 8 השכבות האחרונות לאימון"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1da5e3a5-66e4-47b6-b529-c75af3545085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Epoch...\n",
      "Train Loss: 3.0345157080544065\n",
      "Test Loss:  1.4143547608250455  Accuracy:  42.40115321252059 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 3.014421894284667\n",
      "Test Loss:  1.4113532427503965  Accuracy:  41.989291598023065 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.9942449185004185\n",
      "Test Loss:  1.4017895075094549  Accuracy:  42.27759472817134 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.9729334443849638\n",
      "Test Loss:  1.3931486952960574  Accuracy:  42.46293245469522 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.9481275182516855\n",
      "Test Loss:  1.3774592519983417  Accuracy:  43.266062602965405 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.9227969088238286\n",
      "Test Loss:  1.3842583200322893  Accuracy:  43.59555189456343 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.917777126027095\n",
      "Test Loss:  1.375055820548484  Accuracy:  43.80148270181219 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.9136368784480773\n",
      "Test Loss:  1.3774348401552532  Accuracy:  43.121911037891266 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.903555955133586\n",
      "Test Loss:  1.3749436784025981  Accuracy:  43.78088962108732 %\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.885972878828708\n",
      "Test Loss:  1.3602184112721  Accuracy:  43.76029654036244 %\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "Train_loss = []\n",
    "Test_loss = []\n",
    "Test_acc = []\n",
    "\n",
    "try:\n",
    "    for i in range(n_epochs):\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, scheduler)  \n",
    "        test_loss, test_acc = test_model(model, test_loader, criterion)\n",
    "        \n",
    "        Train_loss.append(train_loss)\n",
    "        Test_loss.append(test_loss)\n",
    "        Test_acc.append(test_acc)\n",
    "        \n",
    "        print('*' * 60)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error during training:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cd0ea5b-f369-4a6d-a857-fd818e2605d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"test_3.pth\")\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75d30e41-4bb5-4bd7-aa40-0c76071b5df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " קצב הלמידה החדש: 0.000002\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.881522145695007\n",
      "Test Loss:  1.3700622755650573  Accuracy:  44.501647446457994 %\n",
      "Epoch 1/10 - LR: 0.000002\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.881600156321344\n",
      "Test Loss:  1.373570790916303  Accuracy:  44.02800658978583 %\n",
      "Epoch 2/10 - LR: 0.000002\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.8763106306449986\n",
      "Test Loss:  1.3696628178460641  Accuracy:  43.5337726523888 %\n",
      "Epoch 3/10 - LR: 0.000002\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.8775617847657844\n",
      "Test Loss:  1.3702311986592324  Accuracy:  43.121911037891266 %\n",
      "Epoch 4/10 - LR: 0.000002\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.871445537117876\n",
      "Test Loss:  1.3695443695455747  Accuracy:  43.76029654036244 %\n",
      "Epoch 5/10 - LR: 0.000001\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.8752944240785285\n",
      "Test Loss:  1.3572298057997345  Accuracy:  43.90444810543657 %\n",
      "Epoch 6/10 - LR: 0.000001\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.8704466157302533\n",
      "Test Loss:  1.375177799394336  Accuracy:  43.80148270181219 %\n",
      "Epoch 7/10 - LR: 0.000001\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.8687434156119234\n",
      "Test Loss:  1.3660062748218962  Accuracy:  44.542833607907745 %\n",
      "Epoch 8/10 - LR: 0.000001\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.8694125338232905\n",
      "Test Loss:  1.3636917375206778  Accuracy:  43.36902800658979 %\n",
      "Epoch 9/10 - LR: 0.000001\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.8692785521656567\n",
      "Test Loss:  1.3668846754496458  Accuracy:  43.78088962108732 %\n",
      "Epoch 10/10 - LR: 0.000001\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "# עדכון קצב הלמידה - נקטין ב-50%\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] *= 0.5  # מקטין פי 2\n",
    "\n",
    "print(f\" קצב הלמידה החדש: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "# אימון נוסף עם 10 אפוקים\n",
    "n_epochs_continue = 10\n",
    "try:\n",
    "    for i in range(n_epochs_continue):\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, scheduler)  \n",
    "        test_loss, test_acc = test_model(model, test_loader, criterion)\n",
    "        \n",
    "        Train_loss.append(train_loss)\n",
    "        Test_loss.append(test_loss)\n",
    "        Test_acc.append(test_acc)\n",
    "\n",
    "        print(f\"Epoch {i+1}/{n_epochs_continue} - LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        print('*' * 60)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error during training:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f4a637f-7c37-4a5d-b1d0-9fcd55d7ef64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"test_4.pth\")\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a626472-c5b0-44f3-9c81-6d099d46198e",
   "metadata": {},
   "source": [
    "✔ אם ה-Test Loss לא יורד משמעותית והדיוק לא משתפר יותר.\n",
    "✔ אם ה-LR הנוכחי מאוד נמוך (למשל 0.000009 כמו שהיה לך).\n",
    "✔ אם המודל עוד לא הגיע ל-Overfitting (ה-Train Loss ו-Test Loss דומים)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dae85ef8-4576-4425-a147-b1e89b83aaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " קצב הלמידה החדש: 0.000050\n"
     ]
    }
   ],
   "source": [
    "# העלאת קצב הלמידה כדי לאפשר למודל ללמוד מהר יותר\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = 0.00005  # הגדלת קצב הלמידה\n",
    "print(f\" קצב הלמידה החדש: {optimizer.param_groups[0]['lr']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91d02009-e68e-4933-a1fd-bc3f2009ba27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Epoch...\n",
      "Train Loss: 2.897140506964981\n",
      "Test Loss:  1.3510410382145719  Accuracy:  44.64579901153213 %\n",
      "Epoch 1/10 - LR: 0.000050\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.860440217221237\n",
      "Test Loss:  1.3494486018531917  Accuracy:  45.716639209225704 %\n",
      "Epoch 2/10 - LR: 0.000050\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.8197179889813464\n",
      "Test Loss:  1.3443392409256045  Accuracy:  45.11943986820428 %\n",
      "Epoch 3/10 - LR: 0.000050\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.790063894013592\n",
      "Test Loss:  1.3342764895456634  Accuracy:  45.42833607907743 %\n",
      "Epoch 4/10 - LR: 0.000050\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.7610946802897915\n",
      "Test Loss:  1.3261105812487044  Accuracy:  45.94316309719934 %\n",
      "Epoch 5/10 - LR: 0.000025\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.7152804953423137\n",
      "Test Loss:  1.305426397511922  Accuracy:  46.47858319604613 %\n",
      "Epoch 6/10 - LR: 0.000025\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.6980430015555896\n",
      "Test Loss:  1.3042666938980814  Accuracy:  45.22240527182866 %\n",
      "Epoch 7/10 - LR: 0.000025\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.669599019253708\n",
      "Test Loss:  1.2968991323990278  Accuracy:  47.17874794069193 %\n",
      "Epoch 8/10 - LR: 0.000025\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.6582925871161716\n",
      "Test Loss:  1.3038577159133717  Accuracy:  47.32289950576607 %\n",
      "Epoch 9/10 - LR: 0.000025\n",
      "************************************************************\n",
      "Starting Training Epoch...\n",
      "Train Loss: 2.629689864110207\n",
      "Test Loss:  1.2824232255454124  Accuracy:  47.26112026359143 %\n",
      "Epoch 10/10 - LR: 0.000013\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "# אימון נוסף עם 10 אפוקים\n",
    "n_epochs_continue = 10\n",
    "try:\n",
    "    for i in range(n_epochs_continue):\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, scheduler)  \n",
    "        test_loss, test_acc = test_model(model, test_loader, criterion)\n",
    "        \n",
    "        Train_loss.append(train_loss)\n",
    "        Test_loss.append(test_loss)\n",
    "        Test_acc.append(test_acc)\n",
    "\n",
    "        print(f\"Epoch {i+1}/{n_epochs_continue} - LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        print('*' * 60)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error during training:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16a26e99-b0db-4ab1-ba36-dd9dbbf63c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1cc985a-4771-43b4-98a2-26c486adce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now with more Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3982303-df42-4d98-939c-67ad40ae80ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.75, 1.0)),  # זום אקראי\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # הפיכה אופקית\n",
    "    transforms.RandomRotation(degrees=30),  # סיבוב חזק יותר\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),  # התאמות צבע\n",
    "    transforms.RandomAffine(degrees=0, shear=10, scale=(0.9, 1.1)),  # עיוות גזירה (Shear)\n",
    "    transforms.RandomErasing(p=0.3),  # מחיקה רנדומלית להוספת רעש\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9276999c-9644-4f27-83a2-a7524d60400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# חלוקת הדאטה לאימון ולמבחן (כמו קודם)\n",
    "dataset_size = len(cars_dataset)\n",
    "train_size = int(0.7 * dataset_size)  # 70% לאימון\n",
    "test_size = dataset_size - train_size  # 30% למבחן\n",
    "\n",
    "train_indices, test_indices = train_test_split(range(dataset_size), train_size=train_size, test_size=test_size, random_state=42)\n",
    "\n",
    "# יצירת תת-סטים עם Augmentation מתאים\n",
    "train_dataset = Subset(cars_dataset, train_indices)\n",
    "test_dataset = Subset(cars_dataset, test_indices)\n",
    "\n",
    "# עדכון הטרנספורמציות\n",
    "train_dataset.dataset.transform = train_transform\n",
    "test_dataset.dataset.transform = test_transform\n",
    "\n",
    "# יצירת DataLoader\n",
    "batch_size = 32  # if it work\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb5e5d3-d2ca-4b44-9e79-52d563f75147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf8ce9b-232f-4454-84ea-de4ea73d5532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
