{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2a261ae-2edc-48e1-a722-35129e5a1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a873869-6228-47a2-8089-1e5689816571",
   "metadata": {},
   "source": [
    "import psutil\n",
    "print(f\" CPU Usage: {psutil.cpu_percent()}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7395cb16-337f-4852-9d38-8d3e8f04d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# טעינת הנתונים מ-TFRecord והכנתם ל-PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819fcaec-044d-4031-9974-a09155e15102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 8144 training images and 8041 test images.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import faiss\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#  נתיב לתיקיית Cars196\n",
    "data_dir = r\"C:\\Users\\revit\\Documents\\Data Learning\\cars196\"\n",
    "\n",
    "# 🔹 רשימת קבצי ה-TFRecord\n",
    "train_files = [os.path.join(data_dir, f\"cars196-train.tfrecord-0000{i}-of-00008\") for i in range(8)]\n",
    "test_files = [os.path.join(data_dir, f\"cars196-test.tfrecord-0000{i}-of-00008\") for i in range(8)]\n",
    "\n",
    "#  פונקציה לקריאת TFRecord\n",
    "def parse_tfrecord(example):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    parsed_example = tf.io.parse_single_example(example, feature_description)\n",
    "    image = tf.image.decode_jpeg(parsed_example['image'], channels=3)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    label = parsed_example['label']\n",
    "    return image, label\n",
    "\n",
    "def load_tfrecord_dataset(filenames):\n",
    "    raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = raw_dataset.map(parse_tfrecord)\n",
    "    return list(dataset)  # ממירים לרשימה לשימוש ב-PyTorch\n",
    "\n",
    "#  טעינת ה-Train/Test מ-TFRecord\n",
    "train_data = [(image.numpy().astype('uint8'), label.numpy()) for image, label in load_tfrecord_dataset(train_files)]\n",
    "test_data = [(image.numpy().astype('uint8'), label.numpy()) for image, label in load_tfrecord_dataset(test_files)]\n",
    "\n",
    "print(f\" Loaded {len(train_data)} training images and {len(test_data)} test images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ab5d26-12e6-446d-a00e-2cb1940f5fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# יצירת PyTorch Dataset ו-DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a84e07a8-7669-46f3-b4e9-3541fc41ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  מחלקת Dataset מותאמת ל-PyTorch\n",
    "class Cars196Dataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_np, label = self.data[idx]\n",
    "        image = Image.fromarray(image_np)  # ממירים ל-PIL\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# 🔹 טרנספורמציות ל-ResNet50\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 🔹 יצירת ה-Datasets וה-DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = Cars196Dataset(train_data, transform=transform)\n",
    "test_dataset = Cars196Dataset(test_data, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=64, shuffle=True, num_workers=0  # הסרנו persistent_workers\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=64, shuffle=False, num_workers=0  # הסרנו persistent_workers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77bd93a-dd90-4f03-9d0f-f1ce88c7eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-Tuning של ResNet50 על Cars196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c52495ee-d992-4fbd-9d70-f3f4b917d1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Starting training...\n",
      "✅ Epoch 1/5 started.\n",
      "Processing Batch 0/128...\n",
      "✅ Epoch 1/5, Batch 0/128, Loss: 5.2937\n",
      "Processing Batch 1/128...\n",
      "Processing Batch 2/128...\n",
      "Processing Batch 3/128...\n",
      "Processing Batch 4/128...\n",
      "Processing Batch 5/128...\n",
      "Processing Batch 6/128...\n",
      "Processing Batch 7/128...\n",
      "Processing Batch 8/128...\n",
      "Processing Batch 9/128...\n",
      "Processing Batch 10/128...\n",
      "✅ Epoch 1/5, Batch 10/128, Loss: 5.2638\n",
      "Processing Batch 11/128...\n",
      "Processing Batch 12/128...\n",
      "Processing Batch 13/128...\n",
      "Processing Batch 14/128...\n",
      "Processing Batch 15/128...\n",
      "Processing Batch 16/128...\n",
      "Processing Batch 17/128...\n",
      "Processing Batch 18/128...\n",
      "Processing Batch 19/128...\n",
      "Processing Batch 20/128...\n",
      "✅ Epoch 1/5, Batch 20/128, Loss: 5.2624\n",
      "Processing Batch 21/128...\n",
      "Processing Batch 22/128...\n",
      "Processing Batch 23/128...\n",
      "Processing Batch 24/128...\n",
      "Processing Batch 25/128...\n",
      "Processing Batch 26/128...\n",
      "Processing Batch 27/128...\n",
      "Processing Batch 28/128...\n",
      "Processing Batch 29/128...\n",
      "Processing Batch 30/128...\n",
      "✅ Epoch 1/5, Batch 30/128, Loss: 5.2626\n",
      "Processing Batch 31/128...\n",
      "Processing Batch 32/128...\n",
      "Processing Batch 33/128...\n",
      "Processing Batch 34/128...\n",
      "Processing Batch 35/128...\n",
      "Processing Batch 36/128...\n",
      "Processing Batch 37/128...\n",
      "Processing Batch 38/128...\n",
      "Processing Batch 39/128...\n",
      "Processing Batch 40/128...\n",
      "✅ Epoch 1/5, Batch 40/128, Loss: 5.1961\n",
      "Processing Batch 41/128...\n",
      "Processing Batch 42/128...\n",
      "Processing Batch 43/128...\n",
      "Processing Batch 44/128...\n",
      "Processing Batch 45/128...\n",
      "Processing Batch 46/128...\n",
      "Processing Batch 47/128...\n",
      "Processing Batch 48/128...\n",
      "Processing Batch 49/128...\n",
      "Processing Batch 50/128...\n",
      "✅ Epoch 1/5, Batch 50/128, Loss: 5.0705\n",
      "Processing Batch 51/128...\n",
      "Processing Batch 52/128...\n",
      "Processing Batch 53/128...\n",
      "Processing Batch 54/128...\n",
      "Processing Batch 55/128...\n",
      "Processing Batch 56/128...\n",
      "Processing Batch 57/128...\n",
      "Processing Batch 58/128...\n",
      "Processing Batch 59/128...\n",
      "Processing Batch 60/128...\n",
      "✅ Epoch 1/5, Batch 60/128, Loss: 4.9842\n",
      "Processing Batch 61/128...\n",
      "Processing Batch 62/128...\n",
      "Processing Batch 63/128...\n",
      "Processing Batch 64/128...\n",
      "Processing Batch 65/128...\n",
      "Processing Batch 66/128...\n",
      "Processing Batch 67/128...\n",
      "Processing Batch 68/128...\n",
      "Processing Batch 69/128...\n",
      "Processing Batch 70/128...\n",
      "✅ Epoch 1/5, Batch 70/128, Loss: 4.8144\n",
      "Processing Batch 71/128...\n",
      "Processing Batch 72/128...\n",
      "Processing Batch 73/128...\n",
      "Processing Batch 74/128...\n",
      "Processing Batch 75/128...\n",
      "Processing Batch 76/128...\n",
      "Processing Batch 77/128...\n",
      "Processing Batch 78/128...\n",
      "Processing Batch 79/128...\n",
      "Processing Batch 80/128...\n",
      "✅ Epoch 1/5, Batch 80/128, Loss: 4.6754\n",
      "Processing Batch 81/128...\n",
      "Processing Batch 82/128...\n",
      "Processing Batch 83/128...\n",
      "Processing Batch 84/128...\n",
      "Processing Batch 85/128...\n",
      "Processing Batch 86/128...\n",
      "Processing Batch 87/128...\n",
      "Processing Batch 88/128...\n",
      "Processing Batch 89/128...\n",
      "Processing Batch 90/128...\n",
      "✅ Epoch 1/5, Batch 90/128, Loss: 4.6083\n",
      "Processing Batch 91/128...\n",
      "Processing Batch 92/128...\n",
      "Processing Batch 93/128...\n",
      "Processing Batch 94/128...\n",
      "Processing Batch 95/128...\n",
      "Processing Batch 96/128...\n",
      "Processing Batch 97/128...\n",
      "Processing Batch 98/128...\n",
      "Processing Batch 99/128...\n",
      "Processing Batch 100/128...\n",
      "✅ Epoch 1/5, Batch 100/128, Loss: 4.3510\n",
      "Processing Batch 101/128...\n",
      "Processing Batch 102/128...\n",
      "Processing Batch 103/128...\n",
      "Processing Batch 104/128...\n",
      "Processing Batch 105/128...\n",
      "Processing Batch 106/128...\n",
      "Processing Batch 107/128...\n",
      "Processing Batch 108/128...\n",
      "Processing Batch 109/128...\n",
      "Processing Batch 110/128...\n",
      "✅ Epoch 1/5, Batch 110/128, Loss: 4.0905\n",
      "Processing Batch 111/128...\n",
      "Processing Batch 112/128...\n",
      "Processing Batch 113/128...\n",
      "Processing Batch 114/128...\n",
      "Processing Batch 115/128...\n",
      "Processing Batch 116/128...\n",
      "Processing Batch 117/128...\n",
      "Processing Batch 118/128...\n",
      "Processing Batch 119/128...\n",
      "Processing Batch 120/128...\n",
      "✅ Epoch 1/5, Batch 120/128, Loss: 4.0015\n",
      "Processing Batch 121/128...\n",
      "Processing Batch 122/128...\n",
      "Processing Batch 123/128...\n",
      "Processing Batch 124/128...\n",
      "Processing Batch 125/128...\n",
      "Processing Batch 126/128...\n",
      "Processing Batch 127/128...\n",
      "✅ Epoch 1/5 Completed! Loss: 4.7957, Accuracy: 0.0732\n",
      "✅ Model checkpoint saved at epoch 1\n",
      "✅ Epoch 2/5 started.\n",
      "Processing Batch 0/128...\n",
      "✅ Epoch 2/5, Batch 0/128, Loss: 3.4030\n",
      "Processing Batch 1/128...\n",
      "Processing Batch 2/128...\n",
      "Processing Batch 3/128...\n",
      "Processing Batch 4/128...\n",
      "Processing Batch 5/128...\n",
      "Processing Batch 6/128...\n",
      "Processing Batch 7/128...\n",
      "Processing Batch 8/128...\n",
      "Processing Batch 9/128...\n",
      "Processing Batch 10/128...\n",
      "✅ Epoch 2/5, Batch 10/128, Loss: 3.3595\n",
      "Processing Batch 11/128...\n",
      "Processing Batch 12/128...\n",
      "Processing Batch 13/128...\n",
      "Processing Batch 14/128...\n",
      "Processing Batch 15/128...\n",
      "Processing Batch 16/128...\n",
      "Processing Batch 17/128...\n",
      "Processing Batch 18/128...\n",
      "Processing Batch 19/128...\n",
      "Processing Batch 20/128...\n",
      "✅ Epoch 2/5, Batch 20/128, Loss: 3.4519\n",
      "Processing Batch 21/128...\n",
      "Processing Batch 22/128...\n",
      "Processing Batch 23/128...\n",
      "Processing Batch 24/128...\n",
      "Processing Batch 25/128...\n",
      "Processing Batch 26/128...\n",
      "Processing Batch 27/128...\n",
      "Processing Batch 28/128...\n",
      "Processing Batch 29/128...\n",
      "Processing Batch 30/128...\n",
      "✅ Epoch 2/5, Batch 30/128, Loss: 3.0144\n",
      "Processing Batch 31/128...\n",
      "Processing Batch 32/128...\n",
      "Processing Batch 33/128...\n",
      "Processing Batch 34/128...\n",
      "Processing Batch 35/128...\n",
      "Processing Batch 36/128...\n",
      "Processing Batch 37/128...\n",
      "Processing Batch 38/128...\n",
      "Processing Batch 39/128...\n",
      "Processing Batch 40/128...\n",
      "✅ Epoch 2/5, Batch 40/128, Loss: 2.6084\n",
      "Processing Batch 41/128...\n",
      "Processing Batch 42/128...\n",
      "Processing Batch 43/128...\n",
      "Processing Batch 44/128...\n",
      "Processing Batch 45/128...\n",
      "Processing Batch 46/128...\n",
      "Processing Batch 47/128...\n",
      "Processing Batch 48/128...\n",
      "Processing Batch 49/128...\n",
      "Processing Batch 50/128...\n",
      "✅ Epoch 2/5, Batch 50/128, Loss: 2.5906\n",
      "Processing Batch 51/128...\n",
      "Processing Batch 52/128...\n",
      "Processing Batch 53/128...\n",
      "Processing Batch 54/128...\n",
      "Processing Batch 55/128...\n",
      "Processing Batch 56/128...\n",
      "Processing Batch 57/128...\n",
      "Processing Batch 58/128...\n",
      "Processing Batch 59/128...\n",
      "Processing Batch 60/128...\n",
      "✅ Epoch 2/5, Batch 60/128, Loss: 2.3268\n",
      "Processing Batch 61/128...\n",
      "Processing Batch 62/128...\n",
      "Processing Batch 63/128...\n",
      "Processing Batch 64/128...\n",
      "Processing Batch 65/128...\n",
      "Processing Batch 66/128...\n",
      "Processing Batch 67/128...\n",
      "Processing Batch 68/128...\n",
      "Processing Batch 69/128...\n",
      "Processing Batch 70/128...\n",
      "✅ Epoch 2/5, Batch 70/128, Loss: 2.4442\n",
      "Processing Batch 71/128...\n",
      "Processing Batch 72/128...\n",
      "Processing Batch 73/128...\n",
      "Processing Batch 74/128...\n",
      "Processing Batch 75/128...\n",
      "Processing Batch 76/128...\n",
      "Processing Batch 77/128...\n",
      "Processing Batch 78/128...\n",
      "Processing Batch 79/128...\n",
      "Processing Batch 80/128...\n",
      "✅ Epoch 2/5, Batch 80/128, Loss: 2.3569\n",
      "Processing Batch 81/128...\n",
      "Processing Batch 82/128...\n",
      "Processing Batch 83/128...\n",
      "Processing Batch 84/128...\n",
      "Processing Batch 85/128...\n",
      "Processing Batch 86/128...\n",
      "Processing Batch 87/128...\n",
      "Processing Batch 88/128...\n",
      "Processing Batch 89/128...\n",
      "Processing Batch 90/128...\n",
      "✅ Epoch 2/5, Batch 90/128, Loss: 1.9936\n",
      "Processing Batch 91/128...\n",
      "Processing Batch 92/128...\n",
      "Processing Batch 93/128...\n",
      "Processing Batch 94/128...\n",
      "Processing Batch 95/128...\n",
      "Processing Batch 96/128...\n",
      "Processing Batch 97/128...\n",
      "Processing Batch 98/128...\n",
      "Processing Batch 99/128...\n",
      "Processing Batch 100/128...\n",
      "✅ Epoch 2/5, Batch 100/128, Loss: 2.0435\n",
      "Processing Batch 101/128...\n",
      "Processing Batch 102/128...\n",
      "Processing Batch 103/128...\n",
      "Processing Batch 104/128...\n",
      "Processing Batch 105/128...\n",
      "Processing Batch 106/128...\n",
      "Processing Batch 107/128...\n",
      "Processing Batch 108/128...\n",
      "Processing Batch 109/128...\n",
      "Processing Batch 110/128...\n",
      "✅ Epoch 2/5, Batch 110/128, Loss: 1.8844\n",
      "Processing Batch 111/128...\n",
      "Processing Batch 112/128...\n",
      "Processing Batch 113/128...\n",
      "Processing Batch 114/128...\n",
      "Processing Batch 115/128...\n",
      "Processing Batch 116/128...\n",
      "Processing Batch 117/128...\n",
      "Processing Batch 118/128...\n",
      "Processing Batch 119/128...\n",
      "Processing Batch 120/128...\n",
      "✅ Epoch 2/5, Batch 120/128, Loss: 1.8331\n",
      "Processing Batch 121/128...\n",
      "Processing Batch 122/128...\n",
      "Processing Batch 123/128...\n",
      "Processing Batch 124/128...\n",
      "Processing Batch 125/128...\n",
      "Processing Batch 126/128...\n",
      "Processing Batch 127/128...\n",
      "✅ Epoch 2/5 Completed! Loss: 2.5434, Accuracy: 0.5007\n",
      "✅ Model checkpoint saved at epoch 2\n",
      "✅ Epoch 3/5 started.\n",
      "Processing Batch 0/128...\n",
      "✅ Epoch 3/5, Batch 0/128, Loss: 1.2751\n",
      "Processing Batch 1/128...\n",
      "Processing Batch 2/128...\n",
      "Processing Batch 3/128...\n",
      "Processing Batch 4/128...\n",
      "Processing Batch 5/128...\n",
      "Processing Batch 6/128...\n",
      "Processing Batch 7/128...\n",
      "Processing Batch 8/128...\n",
      "Processing Batch 9/128...\n",
      "Processing Batch 10/128...\n",
      "✅ Epoch 3/5, Batch 10/128, Loss: 1.2865\n",
      "Processing Batch 11/128...\n",
      "Processing Batch 12/128...\n",
      "Processing Batch 13/128...\n",
      "Processing Batch 14/128...\n",
      "Processing Batch 15/128...\n",
      "Processing Batch 16/128...\n",
      "Processing Batch 17/128...\n",
      "Processing Batch 18/128...\n",
      "Processing Batch 19/128...\n",
      "Processing Batch 20/128...\n",
      "✅ Epoch 3/5, Batch 20/128, Loss: 1.1706\n",
      "Processing Batch 21/128...\n",
      "Processing Batch 22/128...\n",
      "Processing Batch 23/128...\n",
      "Processing Batch 24/128...\n",
      "Processing Batch 25/128...\n",
      "Processing Batch 26/128...\n",
      "Processing Batch 27/128...\n",
      "Processing Batch 28/128...\n",
      "Processing Batch 29/128...\n",
      "Processing Batch 30/128...\n",
      "✅ Epoch 3/5, Batch 30/128, Loss: 1.2260\n",
      "Processing Batch 31/128...\n",
      "Processing Batch 32/128...\n",
      "Processing Batch 33/128...\n",
      "Processing Batch 34/128...\n",
      "Processing Batch 35/128...\n",
      "Processing Batch 36/128...\n",
      "Processing Batch 37/128...\n",
      "Processing Batch 38/128...\n",
      "Processing Batch 39/128...\n",
      "Processing Batch 40/128...\n",
      "✅ Epoch 3/5, Batch 40/128, Loss: 0.9322\n",
      "Processing Batch 41/128...\n",
      "Processing Batch 42/128...\n",
      "Processing Batch 43/128...\n",
      "Processing Batch 44/128...\n",
      "Processing Batch 45/128...\n",
      "Processing Batch 46/128...\n",
      "Processing Batch 47/128...\n",
      "Processing Batch 48/128...\n",
      "Processing Batch 49/128...\n",
      "Processing Batch 50/128...\n",
      "✅ Epoch 3/5, Batch 50/128, Loss: 0.9519\n",
      "Processing Batch 51/128...\n",
      "Processing Batch 52/128...\n",
      "Processing Batch 53/128...\n",
      "Processing Batch 54/128...\n",
      "Processing Batch 55/128...\n",
      "Processing Batch 56/128...\n",
      "Processing Batch 57/128...\n",
      "Processing Batch 58/128...\n",
      "Processing Batch 59/128...\n",
      "Processing Batch 60/128...\n",
      "✅ Epoch 3/5, Batch 60/128, Loss: 0.8243\n",
      "Processing Batch 61/128...\n",
      "Processing Batch 62/128...\n",
      "Processing Batch 63/128...\n",
      "Processing Batch 64/128...\n",
      "Processing Batch 65/128...\n",
      "Processing Batch 66/128...\n",
      "Processing Batch 67/128...\n",
      "Processing Batch 68/128...\n",
      "Processing Batch 69/128...\n",
      "Processing Batch 70/128...\n",
      "✅ Epoch 3/5, Batch 70/128, Loss: 0.9213\n",
      "Processing Batch 71/128...\n",
      "Processing Batch 72/128...\n",
      "Processing Batch 73/128...\n",
      "Processing Batch 74/128...\n",
      "Processing Batch 75/128...\n",
      "Processing Batch 76/128...\n",
      "Processing Batch 77/128...\n",
      "Processing Batch 78/128...\n",
      "Processing Batch 79/128...\n",
      "Processing Batch 80/128...\n",
      "✅ Epoch 3/5, Batch 80/128, Loss: 0.9150\n",
      "Processing Batch 81/128...\n",
      "Processing Batch 82/128...\n",
      "Processing Batch 83/128...\n",
      "Processing Batch 84/128...\n",
      "Processing Batch 85/128...\n",
      "Processing Batch 86/128...\n",
      "Processing Batch 87/128...\n",
      "Processing Batch 88/128...\n",
      "Processing Batch 89/128...\n",
      "Processing Batch 90/128...\n",
      "✅ Epoch 3/5, Batch 90/128, Loss: 0.8990\n",
      "Processing Batch 91/128...\n",
      "Processing Batch 92/128...\n",
      "Processing Batch 93/128...\n",
      "Processing Batch 94/128...\n",
      "Processing Batch 95/128...\n",
      "Processing Batch 96/128...\n",
      "Processing Batch 97/128...\n",
      "Processing Batch 98/128...\n",
      "Processing Batch 99/128...\n",
      "Processing Batch 100/128...\n",
      "✅ Epoch 3/5, Batch 100/128, Loss: 0.6666\n",
      "Processing Batch 101/128...\n",
      "Processing Batch 102/128...\n",
      "Processing Batch 103/128...\n",
      "Processing Batch 104/128...\n",
      "Processing Batch 105/128...\n",
      "Processing Batch 106/128...\n",
      "Processing Batch 107/128...\n",
      "Processing Batch 108/128...\n",
      "Processing Batch 109/128...\n",
      "Processing Batch 110/128...\n",
      "✅ Epoch 3/5, Batch 110/128, Loss: 0.7638\n",
      "Processing Batch 111/128...\n",
      "Processing Batch 112/128...\n",
      "Processing Batch 113/128...\n",
      "Processing Batch 114/128...\n",
      "Processing Batch 115/128...\n",
      "Processing Batch 116/128...\n",
      "Processing Batch 117/128...\n",
      "Processing Batch 118/128...\n",
      "Processing Batch 119/128...\n",
      "Processing Batch 120/128...\n",
      "✅ Epoch 3/5, Batch 120/128, Loss: 0.6652\n",
      "Processing Batch 121/128...\n",
      "Processing Batch 122/128...\n",
      "Processing Batch 123/128...\n",
      "Processing Batch 124/128...\n",
      "Processing Batch 125/128...\n",
      "Processing Batch 126/128...\n",
      "Processing Batch 127/128...\n",
      "✅ Epoch 3/5 Completed! Loss: 0.9487, Accuracy: 0.8353\n",
      "✅ Model checkpoint saved at epoch 3\n",
      "✅ Epoch 4/5 started.\n",
      "Processing Batch 0/128...\n",
      "✅ Epoch 4/5, Batch 0/128, Loss: 0.4769\n",
      "Processing Batch 1/128...\n",
      "Processing Batch 2/128...\n",
      "Processing Batch 3/128...\n",
      "Processing Batch 4/128...\n",
      "Processing Batch 5/128...\n",
      "Processing Batch 6/128...\n",
      "Processing Batch 7/128...\n",
      "Processing Batch 8/128...\n",
      "Processing Batch 9/128...\n",
      "Processing Batch 10/128...\n",
      "✅ Epoch 4/5, Batch 10/128, Loss: 0.3771\n",
      "Processing Batch 11/128...\n",
      "Processing Batch 12/128...\n",
      "Processing Batch 13/128...\n",
      "Processing Batch 14/128...\n",
      "Processing Batch 15/128...\n",
      "Processing Batch 16/128...\n",
      "Processing Batch 17/128...\n",
      "Processing Batch 18/128...\n",
      "Processing Batch 19/128...\n",
      "Processing Batch 20/128...\n",
      "✅ Epoch 4/5, Batch 20/128, Loss: 0.3609\n",
      "Processing Batch 21/128...\n",
      "Processing Batch 22/128...\n",
      "Processing Batch 23/128...\n",
      "Processing Batch 24/128...\n",
      "Processing Batch 25/128...\n",
      "Processing Batch 26/128...\n",
      "Processing Batch 27/128...\n",
      "Processing Batch 28/128...\n",
      "Processing Batch 29/128...\n",
      "Processing Batch 30/128...\n",
      "✅ Epoch 4/5, Batch 30/128, Loss: 0.4047\n",
      "Processing Batch 31/128...\n",
      "Processing Batch 32/128...\n",
      "Processing Batch 33/128...\n",
      "Processing Batch 34/128...\n",
      "Processing Batch 35/128...\n",
      "Processing Batch 36/128...\n",
      "Processing Batch 37/128...\n",
      "Processing Batch 38/128...\n",
      "Processing Batch 39/128...\n",
      "Processing Batch 40/128...\n",
      "✅ Epoch 4/5, Batch 40/128, Loss: 0.2735\n",
      "Processing Batch 41/128...\n",
      "Processing Batch 42/128...\n",
      "Processing Batch 43/128...\n",
      "Processing Batch 44/128...\n",
      "Processing Batch 45/128...\n",
      "Processing Batch 46/128...\n",
      "Processing Batch 47/128...\n",
      "Processing Batch 48/128...\n",
      "Processing Batch 49/128...\n",
      "Processing Batch 50/128...\n",
      "✅ Epoch 4/5, Batch 50/128, Loss: 0.3121\n",
      "Processing Batch 51/128...\n",
      "Processing Batch 52/128...\n",
      "Processing Batch 53/128...\n",
      "Processing Batch 54/128...\n",
      "Processing Batch 55/128...\n",
      "Processing Batch 56/128...\n",
      "Processing Batch 57/128...\n",
      "Processing Batch 58/128...\n",
      "Processing Batch 59/128...\n",
      "Processing Batch 60/128...\n",
      "✅ Epoch 4/5, Batch 60/128, Loss: 0.2400\n",
      "Processing Batch 61/128...\n",
      "Processing Batch 62/128...\n",
      "Processing Batch 63/128...\n",
      "Processing Batch 64/128...\n",
      "Processing Batch 65/128...\n",
      "Processing Batch 66/128...\n",
      "Processing Batch 67/128...\n",
      "Processing Batch 68/128...\n",
      "Processing Batch 69/128...\n",
      "Processing Batch 70/128...\n",
      "✅ Epoch 4/5, Batch 70/128, Loss: 0.3450\n",
      "Processing Batch 71/128...\n",
      "Processing Batch 72/128...\n",
      "Processing Batch 73/128...\n",
      "Processing Batch 74/128...\n",
      "Processing Batch 75/128...\n",
      "Processing Batch 76/128...\n",
      "Processing Batch 77/128...\n",
      "Processing Batch 78/128...\n",
      "Processing Batch 79/128...\n",
      "Processing Batch 80/128...\n",
      "✅ Epoch 4/5, Batch 80/128, Loss: 0.2434\n",
      "Processing Batch 81/128...\n",
      "Processing Batch 82/128...\n",
      "Processing Batch 83/128...\n",
      "Processing Batch 84/128...\n",
      "Processing Batch 85/128...\n",
      "Processing Batch 86/128...\n",
      "Processing Batch 87/128...\n",
      "Processing Batch 88/128...\n",
      "Processing Batch 89/128...\n",
      "Processing Batch 90/128...\n",
      "✅ Epoch 4/5, Batch 90/128, Loss: 0.2623\n",
      "Processing Batch 91/128...\n",
      "Processing Batch 92/128...\n",
      "Processing Batch 93/128...\n",
      "Processing Batch 94/128...\n",
      "Processing Batch 95/128...\n",
      "Processing Batch 96/128...\n",
      "Processing Batch 97/128...\n",
      "Processing Batch 98/128...\n",
      "Processing Batch 99/128...\n",
      "Processing Batch 100/128...\n",
      "✅ Epoch 4/5, Batch 100/128, Loss: 0.3146\n",
      "Processing Batch 101/128...\n",
      "Processing Batch 102/128...\n",
      "Processing Batch 103/128...\n",
      "Processing Batch 104/128...\n",
      "Processing Batch 105/128...\n",
      "Processing Batch 106/128...\n",
      "Processing Batch 107/128...\n",
      "Processing Batch 108/128...\n",
      "Processing Batch 109/128...\n",
      "Processing Batch 110/128...\n",
      "✅ Epoch 4/5, Batch 110/128, Loss: 0.3215\n",
      "Processing Batch 111/128...\n",
      "Processing Batch 112/128...\n",
      "Processing Batch 113/128...\n",
      "Processing Batch 114/128...\n",
      "Processing Batch 115/128...\n",
      "Processing Batch 116/128...\n",
      "Processing Batch 117/128...\n",
      "Processing Batch 118/128...\n",
      "Processing Batch 119/128...\n",
      "Processing Batch 120/128...\n",
      "✅ Epoch 4/5, Batch 120/128, Loss: 0.2287\n",
      "Processing Batch 121/128...\n",
      "Processing Batch 122/128...\n",
      "Processing Batch 123/128...\n",
      "Processing Batch 124/128...\n",
      "Processing Batch 125/128...\n",
      "Processing Batch 126/128...\n",
      "Processing Batch 127/128...\n",
      "✅ Epoch 4/5 Completed! Loss: 0.3193, Accuracy: 0.9586\n",
      "✅ Model checkpoint saved at epoch 4\n",
      "✅ Epoch 5/5 started.\n",
      "Processing Batch 0/128...\n",
      "✅ Epoch 5/5, Batch 0/128, Loss: 0.1261\n",
      "Processing Batch 1/128...\n",
      "Processing Batch 2/128...\n",
      "Processing Batch 3/128...\n",
      "Processing Batch 4/128...\n",
      "Processing Batch 5/128...\n",
      "Processing Batch 6/128...\n",
      "Processing Batch 7/128...\n",
      "Processing Batch 8/128...\n",
      "Processing Batch 9/128...\n",
      "Processing Batch 10/128...\n",
      "✅ Epoch 5/5, Batch 10/128, Loss: 0.1423\n",
      "Processing Batch 11/128...\n",
      "Processing Batch 12/128...\n",
      "Processing Batch 13/128...\n",
      "Processing Batch 14/128...\n",
      "Processing Batch 15/128...\n",
      "Processing Batch 16/128...\n",
      "Processing Batch 17/128...\n",
      "Processing Batch 18/128...\n",
      "Processing Batch 19/128...\n",
      "Processing Batch 20/128...\n",
      "✅ Epoch 5/5, Batch 20/128, Loss: 0.1036\n",
      "Processing Batch 21/128...\n",
      "Processing Batch 22/128...\n",
      "Processing Batch 23/128...\n",
      "Processing Batch 24/128...\n",
      "Processing Batch 25/128...\n",
      "Processing Batch 26/128...\n",
      "Processing Batch 27/128...\n",
      "Processing Batch 28/128...\n",
      "Processing Batch 29/128...\n",
      "Processing Batch 30/128...\n",
      "✅ Epoch 5/5, Batch 30/128, Loss: 0.1092\n",
      "Processing Batch 31/128...\n",
      "Processing Batch 32/128...\n",
      "Processing Batch 33/128...\n",
      "Processing Batch 34/128...\n",
      "Processing Batch 35/128...\n",
      "Processing Batch 36/128...\n",
      "Processing Batch 37/128...\n",
      "Processing Batch 38/128...\n",
      "Processing Batch 39/128...\n",
      "Processing Batch 40/128...\n",
      "✅ Epoch 5/5, Batch 40/128, Loss: 0.1121\n",
      "Processing Batch 41/128...\n",
      "Processing Batch 42/128...\n",
      "Processing Batch 43/128...\n",
      "Processing Batch 44/128...\n",
      "Processing Batch 45/128...\n",
      "Processing Batch 46/128...\n",
      "Processing Batch 47/128...\n",
      "Processing Batch 48/128...\n",
      "Processing Batch 49/128...\n",
      "Processing Batch 50/128...\n",
      "✅ Epoch 5/5, Batch 50/128, Loss: 0.1169\n",
      "Processing Batch 51/128...\n",
      "Processing Batch 52/128...\n",
      "Processing Batch 53/128...\n",
      "Processing Batch 54/128...\n",
      "Processing Batch 55/128...\n",
      "Processing Batch 56/128...\n",
      "Processing Batch 57/128...\n",
      "Processing Batch 58/128...\n",
      "Processing Batch 59/128...\n",
      "Processing Batch 60/128...\n",
      "✅ Epoch 5/5, Batch 60/128, Loss: 0.1040\n",
      "Processing Batch 61/128...\n",
      "Processing Batch 62/128...\n",
      "Processing Batch 63/128...\n",
      "Processing Batch 64/128...\n",
      "Processing Batch 65/128...\n",
      "Processing Batch 66/128...\n",
      "Processing Batch 67/128...\n",
      "Processing Batch 68/128...\n",
      "Processing Batch 69/128...\n",
      "Processing Batch 70/128...\n",
      "✅ Epoch 5/5, Batch 70/128, Loss: 0.1653\n",
      "Processing Batch 71/128...\n",
      "Processing Batch 72/128...\n",
      "Processing Batch 73/128...\n",
      "Processing Batch 74/128...\n",
      "Processing Batch 75/128...\n",
      "Processing Batch 76/128...\n",
      "Processing Batch 77/128...\n",
      "Processing Batch 78/128...\n",
      "Processing Batch 79/128...\n",
      "Processing Batch 80/128...\n",
      "✅ Epoch 5/5, Batch 80/128, Loss: 0.0800\n",
      "Processing Batch 81/128...\n",
      "Processing Batch 82/128...\n",
      "Processing Batch 83/128...\n",
      "Processing Batch 84/128...\n",
      "Processing Batch 85/128...\n",
      "Processing Batch 86/128...\n",
      "Processing Batch 87/128...\n",
      "Processing Batch 88/128...\n",
      "Processing Batch 89/128...\n",
      "Processing Batch 90/128...\n",
      "✅ Epoch 5/5, Batch 90/128, Loss: 0.0774\n",
      "Processing Batch 91/128...\n",
      "Processing Batch 92/128...\n",
      "Processing Batch 93/128...\n",
      "Processing Batch 94/128...\n",
      "Processing Batch 95/128...\n",
      "Processing Batch 96/128...\n",
      "Processing Batch 97/128...\n",
      "Processing Batch 98/128...\n",
      "Processing Batch 99/128...\n",
      "Processing Batch 100/128...\n",
      "✅ Epoch 5/5, Batch 100/128, Loss: 0.1199\n",
      "Processing Batch 101/128...\n",
      "Processing Batch 102/128...\n",
      "Processing Batch 103/128...\n",
      "Processing Batch 104/128...\n",
      "Processing Batch 105/128...\n",
      "Processing Batch 106/128...\n",
      "Processing Batch 107/128...\n",
      "Processing Batch 108/128...\n",
      "Processing Batch 109/128...\n",
      "Processing Batch 110/128...\n",
      "✅ Epoch 5/5, Batch 110/128, Loss: 0.1110\n",
      "Processing Batch 111/128...\n",
      "Processing Batch 112/128...\n",
      "Processing Batch 113/128...\n",
      "Processing Batch 114/128...\n",
      "Processing Batch 115/128...\n",
      "Processing Batch 116/128...\n",
      "Processing Batch 117/128...\n",
      "Processing Batch 118/128...\n",
      "Processing Batch 119/128...\n",
      "Processing Batch 120/128...\n",
      "✅ Epoch 5/5, Batch 120/128, Loss: 0.0900\n",
      "Processing Batch 121/128...\n",
      "Processing Batch 122/128...\n",
      "Processing Batch 123/128...\n",
      "Processing Batch 124/128...\n",
      "Processing Batch 125/128...\n",
      "Processing Batch 126/128...\n",
      "Processing Batch 127/128...\n",
      "✅ Epoch 5/5 Completed! Loss: 0.1103, Accuracy: 0.9917\n",
      "✅ Model checkpoint saved at epoch 5\n",
      "✅ Training Completed!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#  טעינת ResNet50 עם התאמה ל-Cars196\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, len(set(label for _, label in train_data)))  # מספר המחלקות\n",
    "model = model.to(device)\n",
    "\n",
    "#  פונקציית הפסד (Loss) ואופטימיזציה\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "#  אימון הרשת\n",
    "print(\" Starting training...\")\n",
    "num_epochs = 5  \n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    print(f\" Epoch {epoch+1}/{num_epochs} started.\")  # 🛠 האם בכלל התחיל אימון?\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        print(f\"Processing Batch {batch_idx}/{len(train_loader)}...\")  # 🛠 בדיקה לפני העברת הנתונים למודל\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        #  עדכון כל 10 באצ'ים (סטטוס ביניים)\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\" Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    print(f\" Epoch {epoch+1}/{num_epochs} Completed! Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    #  הוספת Checkpoint שמירה בכל סוף Epoch\n",
    "    torch.save(model.state_dict(), f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "    print(f\" Model checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "print(\" Training Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "217ab7e5-a6e3-4116-965f-29c22cd60dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# טעינת המודל המאומן והכנת FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "833fe4b4-cc61-4327-a902-61d747221b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revit\\AppData\\Local\\Temp\\ipykernel_10124\\1072647916.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(\"C:\\\\Users\\\\revit\\\\Documents\\\\Data Learning\\\\Project2\", last_checkpoint), map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded from last checkpoint (Epoch 5).\n"
     ]
    }
   ],
   "source": [
    "last_checkpoint = \"checkpoint_epoch_5.pth\"\n",
    "model.load_state_dict(torch.load(os.path.join(\"C:\\\\Users\\\\revit\\\\Documents\\\\Data Learning\\\\Project2\", last_checkpoint), map_location=device))\n",
    "print(\" Model loaded from last checkpoint (Epoch 5).\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25f505d4-eef8-4461-8b1e-ff39aaba2e4e",
   "metadata": {},
   "source": [
    "#  טעינת המודל המאומן להסרת שכבת הסיווג\n",
    "model.load_state_dict(torch.load(\"fine_tuned_resnet50_cars196.pth\", map_location=device))\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # הסרת שכבת הסיווג\n",
    "model.eval()\n",
    "\n",
    "#  פונקציה לחילוץ מאפיינים\n",
    "def extract_features(image):\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.squeeze().cpu().numpy()\n",
    "\n",
    "#  יצירת FAISS\n",
    "index = faiss.IndexFlatL2(2048)\n",
    "all_features, image_data_list = [], []\n",
    "\n",
    "for image_np, label in train_data:\n",
    "    pil_image = Image.fromarray(image_np)\n",
    "    feature_vector = extract_features(pil_image)\n",
    "    all_features.append(feature_vector)\n",
    "    image_data_list.append((pil_image, label))\n",
    "\n",
    "all_features = np.array(all_features).astype('float32')\n",
    "faiss.normalize_L2(all_features)\n",
    "index.add(all_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c76603-96d3-4207-9110-c75d24717ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  חיפוש תמונות דומות והערכת איכות"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c812008-98d2-435e-a3f9-54fa0d116b29",
   "metadata": {},
   "source": [
    "#  פונקציה לחיפוש דמיון\n",
    "def search_similar(image, index, k=5):\n",
    "    query_vector = extract_features(image).reshape(1, -1).astype('float32')\n",
    "    faiss.normalize_L2(query_vector)\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "    return indices[0], distances\n",
    "\n",
    "#  בחירת תמונה לבדיקה\n",
    "query_image_np, query_label = test_data[0]\n",
    "query_pil_image = Image.fromarray(query_image_np)\n",
    "\n",
    "# 🔹 חיפוש תמונות דומות\n",
    "similar_images, distances = search_similar(query_pil_image, index, k=5)\n",
    "\n",
    "# 🔹 הצגת תוצאות\n",
    "def show_results(query_image, similar_indices, distances):\n",
    "    fig, ax = plt.subplots(1, 6, figsize=(15, 5))\n",
    "    ax[0].imshow(query_image)\n",
    "    ax[0].set_title(\"Query Image\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    for i, (idx, dist) in enumerate(zip(similar_indices, distances[0])):\n",
    "        similar_pil_image, _ = image_data_list[idx]\n",
    "        ax[i+1].imshow(similar_pil_image)\n",
    "        ax[i+1].set_title(f\"Match {i+1} (Score: {dist:.2f})\")\n",
    "        ax[i+1].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_results(query_pil_image, similar_images, distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de13afed-1887-486d-a0c3-6cbd36bb69bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Classification layer removed. Model ready for feature extraction.\n"
     ]
    }
   ],
   "source": [
    "# הסרת שכבת סיווג וחילות מאפפייניפ\n",
    "#  הסרת שכבת הסיווג\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # משאירים רק את ה-Feature Extractor\n",
    "model.eval()\n",
    "print(\" Classification layer removed. Model ready for feature extraction.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2d458e6-1bf9-43bd-aca3-c7b58a1ee175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# פונקציה לחילוץ מאפיינים\n",
    "def extract_features(image):\n",
    "    image = transform(image).unsqueeze(0).to(device)  # המרה לטנסור והוספת Batch Dimension\n",
    "    with torch.no_grad():\n",
    "        features = model(image)  # הרצת המודל\n",
    "    return features.squeeze().cpu().numpy()  # המרה ל-NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e2d35e3-eadc-44ce-92fd-828be815fd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test Accuracy: 0.0313\n"
     ]
    }
   ],
   "source": [
    "#  שלב בדיקת הביצועים על ה-Test Set\n",
    "model.eval()  # מעביר את המודל למצב הערכה (Evaluation)\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():  # אין צורך לחשב גרדיאנטים בבדיקה\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # בוחרים את המחלקה עם הסיכוי הגבוה ביותר\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_accuracy = correct / total  # חישוב הדיוק הסופי\n",
    "print(f\" Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "565fb533-2ec0-4cb4-abf5-e2ac52873779",
   "metadata": {},
   "source": [
    "בעיה חמורה של Overfitting!\n",
    " Test Accuracy = 3.13% לעומת Train Accuracy = 99.17% →\n",
    " זה סימן מובהק שהמודל למד לשנן את הדאטה ולא לבצע הכללה!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95809477-b0c2-4113-b5d9-d9c6055c7ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# יצירת אינדקס FAISS לכל התמונות ב-Train\n",
    "import faiss\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "index = faiss.IndexFlatL2(2048)  # FAISS Index - חיפוש לפי L2 Distance\n",
    "all_features, image_data_list = [], []\n",
    "\n",
    "for image_np, label in train_data:\n",
    "    pil_image = Image.fromarray(image_np)  # המרת NumPy ל-PIL\n",
    "    feature_vector = extract_features(pil_image)  # חילוץ מאפיינים\n",
    "    all_features.append(feature_vector)\n",
    "    image_data_list.append((pil_image, label))  # שמירת התמונה והתגית שלה\n",
    "\n",
    "#  נורמליזציה ושמירת וקטורים באינדקס FAISS\n",
    "all_features = np.array(all_features).astype('float32')\n",
    "faiss.normalize_L2(all_features)\n",
    "index.add(all_features)\n",
    "\n",
    "print(f\" FAISS index built with {len(all_features)} images using fine-tuned model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03736aea-22bc-41a5-93c3-71b4115cc88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# חיפוש תמונות דומות (Image Retrieval)\n",
    "#  בחירת תמונה לבדיקה\n",
    "query_image_np, query_label = test_data[0]\n",
    "query_pil_image = Image.fromarray(query_image_np)\n",
    "\n",
    "#  חיפוש תמונות דומות ב-FAISS\n",
    "def search_similar(image, index, k=5):\n",
    "    query_vector = extract_features(image).reshape(1, -1).astype('float32')\n",
    "    faiss.normalize_L2(query_vector)\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "    return indices[0], distances\n",
    "\n",
    "similar_images, distances = search_similar(query_pil_image, index, k=5)\n",
    "\n",
    "print(\" Similar images found at indices:\", similar_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4493b6-1282-4418-b61a-15a2f96c2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# הצגת התוצאות\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_results(query_image, similar_indices, distances):\n",
    "    fig, ax = plt.subplots(1, 6, figsize=(15, 5))\n",
    "    ax[0].imshow(query_image)\n",
    "    ax[0].set_title(\"Query Image\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    for i, (idx, dist) in enumerate(zip(similar_indices, distances[0])):\n",
    "        similar_pil_image, _ = image_data_list[idx]\n",
    "        ax[i+1].imshow(similar_pil_image)\n",
    "        ax[i+1].set_title(f\"Match {i+1} (Score: {dist:.2f})\")\n",
    "        ax[i+1].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_results(query_pil_image, similar_images, distances)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
