{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2a261ae-2edc-48e1-a722-35129e5a1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a873869-6228-47a2-8089-1e5689816571",
   "metadata": {},
   "source": [
    "import psutil\n",
    "print(f\" CPU Usage: {psutil.cpu_percent()}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7395cb16-337f-4852-9d38-8d3e8f04d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ×˜×¢×™× ×ª ×”× ×ª×•× ×™× ×-TFRecord ×•×”×›× ×ª× ×œ-PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819fcaec-044d-4031-9974-a09155e15102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 8144 training images and 8041 test images.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import faiss\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#  × ×ª×™×‘ ×œ×ª×™×§×™×™×ª Cars196\n",
    "data_dir = r\"C:\\Users\\revit\\Documents\\Data Learning\\cars196\"\n",
    "\n",
    "# ğŸ”¹ ×¨×©×™××ª ×§×‘×¦×™ ×”-TFRecord\n",
    "train_files = [os.path.join(data_dir, f\"cars196-train.tfrecord-0000{i}-of-00008\") for i in range(8)]\n",
    "test_files = [os.path.join(data_dir, f\"cars196-test.tfrecord-0000{i}-of-00008\") for i in range(8)]\n",
    "\n",
    "#  ×¤×•× ×§×¦×™×” ×œ×§×¨×™××ª TFRecord\n",
    "def parse_tfrecord(example):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    parsed_example = tf.io.parse_single_example(example, feature_description)\n",
    "    image = tf.image.decode_jpeg(parsed_example['image'], channels=3)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    label = parsed_example['label']\n",
    "    return image, label\n",
    "\n",
    "def load_tfrecord_dataset(filenames):\n",
    "    raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = raw_dataset.map(parse_tfrecord)\n",
    "    return list(dataset)  # ×××™×¨×™× ×œ×¨×©×™××” ×œ×©×™××•×© ×‘-PyTorch\n",
    "\n",
    "#  ×˜×¢×™× ×ª ×”-Train/Test ×-TFRecord\n",
    "train_data = [(image.numpy().astype('uint8'), label.numpy()) for image, label in load_tfrecord_dataset(train_files)]\n",
    "test_data = [(image.numpy().astype('uint8'), label.numpy()) for image, label in load_tfrecord_dataset(test_files)]\n",
    "\n",
    "print(f\" Loaded {len(train_data)} training images and {len(test_data)} test images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12ab5d26-12e6-446d-a00e-2cb1940f5fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ×™×¦×™×¨×ª PyTorch Dataset ×•-DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a84e07a8-7669-46f3-b4e9-3541fc41ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ××—×œ×§×ª Dataset ××•×ª×××ª ×œ-PyTorch\n",
    "class Cars196Dataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_np, label = self.data[idx]\n",
    "        image = Image.fromarray(image_np)  # ×××™×¨×™× ×œ-PIL\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# ğŸ”¹ ×˜×¨× ×¡×¤×•×¨××¦×™×•×ª ×œ-ResNet50\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ğŸ”¹ ×™×¦×™×¨×ª ×”-Datasets ×•×”-DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = Cars196Dataset(train_data, transform=transform)\n",
    "test_dataset = Cars196Dataset(test_data, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=64, shuffle=True, num_workers=0  # ×”×¡×¨× ×• persistent_workers\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=64, shuffle=False, num_workers=0  # ×”×¡×¨× ×• persistent_workers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77bd93a-dd90-4f03-9d0f-f1ce88c7eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-Tuning ×©×œ ResNet50 ×¢×œ Cars196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c52495ee-d992-4fbd-9d70-f3f4b917d1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Starting training...\n",
      "âœ… Epoch 1/5 started.\n",
      "Processing Batch 0/128...\n",
      "âœ… Epoch 1/5, Batch 0/128, Loss: 5.2937\n",
      "Processing Batch 1/128...\n",
      "Processing Batch 2/128...\n",
      "Processing Batch 3/128...\n",
      "Processing Batch 4/128...\n",
      "Processing Batch 5/128...\n",
      "Processing Batch 6/128...\n",
      "Processing Batch 7/128...\n",
      "Processing Batch 8/128...\n",
      "Processing Batch 9/128...\n",
      "Processing Batch 10/128...\n",
      "âœ… Epoch 1/5, Batch 10/128, Loss: 5.2638\n",
      "Processing Batch 11/128...\n",
      "Processing Batch 12/128...\n",
      "Processing Batch 13/128...\n",
      "Processing Batch 14/128...\n",
      "Processing Batch 15/128...\n",
      "Processing Batch 16/128...\n",
      "Processing Batch 17/128...\n",
      "Processing Batch 18/128...\n",
      "Processing Batch 19/128...\n",
      "Processing Batch 20/128...\n",
      "âœ… Epoch 1/5, Batch 20/128, Loss: 5.2624\n",
      "Processing Batch 21/128...\n",
      "Processing Batch 22/128...\n",
      "Processing Batch 23/128...\n",
      "Processing Batch 24/128...\n",
      "Processing Batch 25/128...\n",
      "Processing Batch 26/128...\n",
      "Processing Batch 27/128...\n",
      "Processing Batch 28/128...\n",
      "Processing Batch 29/128...\n",
      "Processing Batch 30/128...\n",
      "âœ… Epoch 1/5, Batch 30/128, Loss: 5.2626\n",
      "Processing Batch 31/128...\n",
      "Processing Batch 32/128...\n",
      "Processing Batch 33/128...\n",
      "Processing Batch 34/128...\n",
      "Processing Batch 35/128...\n",
      "Processing Batch 36/128...\n",
      "Processing Batch 37/128...\n",
      "Processing Batch 38/128...\n",
      "Processing Batch 39/128...\n",
      "Processing Batch 40/128...\n",
      "âœ… Epoch 1/5, Batch 40/128, Loss: 5.1961\n",
      "Processing Batch 41/128...\n",
      "Processing Batch 42/128...\n",
      "Processing Batch 43/128...\n",
      "Processing Batch 44/128...\n",
      "Processing Batch 45/128...\n",
      "Processing Batch 46/128...\n",
      "Processing Batch 47/128...\n",
      "Processing Batch 48/128...\n",
      "Processing Batch 49/128...\n",
      "Processing Batch 50/128...\n",
      "âœ… Epoch 1/5, Batch 50/128, Loss: 5.0705\n",
      "Processing Batch 51/128...\n",
      "Processing Batch 52/128...\n",
      "Processing Batch 53/128...\n",
      "Processing Batch 54/128...\n",
      "Processing Batch 55/128...\n",
      "Processing Batch 56/128...\n",
      "Processing Batch 57/128...\n",
      "Processing Batch 58/128...\n",
      "Processing Batch 59/128...\n",
      "Processing Batch 60/128...\n",
      "âœ… Epoch 1/5, Batch 60/128, Loss: 4.9842\n",
      "Processing Batch 61/128...\n",
      "Processing Batch 62/128...\n",
      "Processing Batch 63/128...\n",
      "Processing Batch 64/128...\n",
      "Processing Batch 65/128...\n",
      "Processing Batch 66/128...\n",
      "Processing Batch 67/128...\n",
      "Processing Batch 68/128...\n",
      "Processing Batch 69/128...\n",
      "Processing Batch 70/128...\n",
      "âœ… Epoch 1/5, Batch 70/128, Loss: 4.8144\n",
      "Processing Batch 71/128...\n",
      "Processing Batch 72/128...\n",
      "Processing Batch 73/128...\n",
      "Processing Batch 74/128...\n",
      "Processing Batch 75/128...\n",
      "Processing Batch 76/128...\n",
      "Processing Batch 77/128...\n",
      "Processing Batch 78/128...\n",
      "Processing Batch 79/128...\n",
      "Processing Batch 80/128...\n",
      "âœ… Epoch 1/5, Batch 80/128, Loss: 4.6754\n",
      "Processing Batch 81/128...\n",
      "Processing Batch 82/128...\n",
      "Processing Batch 83/128...\n",
      "Processing Batch 84/128...\n",
      "Processing Batch 85/128...\n",
      "Processing Batch 86/128...\n",
      "Processing Batch 87/128...\n",
      "Processing Batch 88/128...\n",
      "Processing Batch 89/128...\n",
      "Processing Batch 90/128...\n",
      "âœ… Epoch 1/5, Batch 90/128, Loss: 4.6083\n",
      "Processing Batch 91/128...\n",
      "Processing Batch 92/128...\n",
      "Processing Batch 93/128...\n",
      "Processing Batch 94/128...\n",
      "Processing Batch 95/128...\n",
      "Processing Batch 96/128...\n",
      "Processing Batch 97/128...\n",
      "Processing Batch 98/128...\n",
      "Processing Batch 99/128...\n",
      "Processing Batch 100/128...\n",
      "âœ… Epoch 1/5, Batch 100/128, Loss: 4.3510\n",
      "Processing Batch 101/128...\n",
      "Processing Batch 102/128...\n",
      "Processing Batch 103/128...\n",
      "Processing Batch 104/128...\n",
      "Processing Batch 105/128...\n",
      "Processing Batch 106/128...\n",
      "Processing Batch 107/128...\n",
      "Processing Batch 108/128...\n",
      "Processing Batch 109/128...\n",
      "Processing Batch 110/128...\n",
      "âœ… Epoch 1/5, Batch 110/128, Loss: 4.0905\n",
      "Processing Batch 111/128...\n",
      "Processing Batch 112/128...\n",
      "Processing Batch 113/128...\n",
      "Processing Batch 114/128...\n",
      "Processing Batch 115/128...\n",
      "Processing Batch 116/128...\n",
      "Processing Batch 117/128...\n",
      "Processing Batch 118/128...\n",
      "Processing Batch 119/128...\n",
      "Processing Batch 120/128...\n",
      "âœ… Epoch 1/5, Batch 120/128, Loss: 4.0015\n",
      "Processing Batch 121/128...\n",
      "Processing Batch 122/128...\n",
      "Processing Batch 123/128...\n",
      "Processing Batch 124/128...\n",
      "Processing Batch 125/128...\n",
      "Processing Batch 126/128...\n",
      "Processing Batch 127/128...\n",
      "âœ… Epoch 1/5 Completed! Loss: 4.7957, Accuracy: 0.0732\n",
      "âœ… Model checkpoint saved at epoch 1\n",
      "âœ… Epoch 2/5 started.\n",
      "Processing Batch 0/128...\n",
      "âœ… Epoch 2/5, Batch 0/128, Loss: 3.4030\n",
      "Processing Batch 1/128...\n",
      "Processing Batch 2/128...\n",
      "Processing Batch 3/128...\n",
      "Processing Batch 4/128...\n",
      "Processing Batch 5/128...\n",
      "Processing Batch 6/128...\n",
      "Processing Batch 7/128...\n",
      "Processing Batch 8/128...\n",
      "Processing Batch 9/128...\n",
      "Processing Batch 10/128...\n",
      "âœ… Epoch 2/5, Batch 10/128, Loss: 3.3595\n",
      "Processing Batch 11/128...\n",
      "Processing Batch 12/128...\n",
      "Processing Batch 13/128...\n",
      "Processing Batch 14/128...\n",
      "Processing Batch 15/128...\n",
      "Processing Batch 16/128...\n",
      "Processing Batch 17/128...\n",
      "Processing Batch 18/128...\n",
      "Processing Batch 19/128...\n",
      "Processing Batch 20/128...\n",
      "âœ… Epoch 2/5, Batch 20/128, Loss: 3.4519\n",
      "Processing Batch 21/128...\n",
      "Processing Batch 22/128...\n",
      "Processing Batch 23/128...\n",
      "Processing Batch 24/128...\n",
      "Processing Batch 25/128...\n",
      "Processing Batch 26/128...\n",
      "Processing Batch 27/128...\n",
      "Processing Batch 28/128...\n",
      "Processing Batch 29/128...\n",
      "Processing Batch 30/128...\n",
      "âœ… Epoch 2/5, Batch 30/128, Loss: 3.0144\n",
      "Processing Batch 31/128...\n",
      "Processing Batch 32/128...\n",
      "Processing Batch 33/128...\n",
      "Processing Batch 34/128...\n",
      "Processing Batch 35/128...\n",
      "Processing Batch 36/128...\n",
      "Processing Batch 37/128...\n",
      "Processing Batch 38/128...\n",
      "Processing Batch 39/128...\n",
      "Processing Batch 40/128...\n",
      "âœ… Epoch 2/5, Batch 40/128, Loss: 2.6084\n",
      "Processing Batch 41/128...\n",
      "Processing Batch 42/128...\n",
      "Processing Batch 43/128...\n",
      "Processing Batch 44/128...\n",
      "Processing Batch 45/128...\n",
      "Processing Batch 46/128...\n",
      "Processing Batch 47/128...\n",
      "Processing Batch 48/128...\n",
      "Processing Batch 49/128...\n",
      "Processing Batch 50/128...\n",
      "âœ… Epoch 2/5, Batch 50/128, Loss: 2.5906\n",
      "Processing Batch 51/128...\n",
      "Processing Batch 52/128...\n",
      "Processing Batch 53/128...\n",
      "Processing Batch 54/128...\n",
      "Processing Batch 55/128...\n",
      "Processing Batch 56/128...\n",
      "Processing Batch 57/128...\n",
      "Processing Batch 58/128...\n",
      "Processing Batch 59/128...\n",
      "Processing Batch 60/128...\n",
      "âœ… Epoch 2/5, Batch 60/128, Loss: 2.3268\n",
      "Processing Batch 61/128...\n",
      "Processing Batch 62/128...\n",
      "Processing Batch 63/128...\n",
      "Processing Batch 64/128...\n",
      "Processing Batch 65/128...\n",
      "Processing Batch 66/128...\n",
      "Processing Batch 67/128...\n",
      "Processing Batch 68/128...\n",
      "Processing Batch 69/128...\n",
      "Processing Batch 70/128...\n",
      "âœ… Epoch 2/5, Batch 70/128, Loss: 2.4442\n",
      "Processing Batch 71/128...\n",
      "Processing Batch 72/128...\n",
      "Processing Batch 73/128...\n",
      "Processing Batch 74/128...\n",
      "Processing Batch 75/128...\n",
      "Processing Batch 76/128...\n",
      "Processing Batch 77/128...\n",
      "Processing Batch 78/128...\n",
      "Processing Batch 79/128...\n",
      "Processing Batch 80/128...\n",
      "âœ… Epoch 2/5, Batch 80/128, Loss: 2.3569\n",
      "Processing Batch 81/128...\n",
      "Processing Batch 82/128...\n",
      "Processing Batch 83/128...\n",
      "Processing Batch 84/128...\n",
      "Processing Batch 85/128...\n",
      "Processing Batch 86/128...\n",
      "Processing Batch 87/128...\n",
      "Processing Batch 88/128...\n",
      "Processing Batch 89/128...\n",
      "Processing Batch 90/128...\n",
      "âœ… Epoch 2/5, Batch 90/128, Loss: 1.9936\n",
      "Processing Batch 91/128...\n",
      "Processing Batch 92/128...\n",
      "Processing Batch 93/128...\n",
      "Processing Batch 94/128...\n",
      "Processing Batch 95/128...\n",
      "Processing Batch 96/128...\n",
      "Processing Batch 97/128...\n",
      "Processing Batch 98/128...\n",
      "Processing Batch 99/128...\n",
      "Processing Batch 100/128...\n",
      "âœ… Epoch 2/5, Batch 100/128, Loss: 2.0435\n",
      "Processing Batch 101/128...\n",
      "Processing Batch 102/128...\n",
      "Processing Batch 103/128...\n",
      "Processing Batch 104/128...\n",
      "Processing Batch 105/128...\n",
      "Processing Batch 106/128...\n",
      "Processing Batch 107/128...\n",
      "Processing Batch 108/128...\n",
      "Processing Batch 109/128...\n",
      "Processing Batch 110/128...\n",
      "âœ… Epoch 2/5, Batch 110/128, Loss: 1.8844\n",
      "Processing Batch 111/128...\n",
      "Processing Batch 112/128...\n",
      "Processing Batch 113/128...\n",
      "Processing Batch 114/128...\n",
      "Processing Batch 115/128...\n",
      "Processing Batch 116/128...\n",
      "Processing Batch 117/128...\n",
      "Processing Batch 118/128...\n",
      "Processing Batch 119/128...\n",
      "Processing Batch 120/128...\n",
      "âœ… Epoch 2/5, Batch 120/128, Loss: 1.8331\n",
      "Processing Batch 121/128...\n",
      "Processing Batch 122/128...\n",
      "Processing Batch 123/128...\n",
      "Processing Batch 124/128...\n",
      "Processing Batch 125/128...\n",
      "Processing Batch 126/128...\n",
      "Processing Batch 127/128...\n",
      "âœ… Epoch 2/5 Completed! Loss: 2.5434, Accuracy: 0.5007\n",
      "âœ… Model checkpoint saved at epoch 2\n",
      "âœ… Epoch 3/5 started.\n",
      "Processing Batch 0/128...\n",
      "âœ… Epoch 3/5, Batch 0/128, Loss: 1.2751\n",
      "Processing Batch 1/128...\n",
      "Processing Batch 2/128...\n",
      "Processing Batch 3/128...\n",
      "Processing Batch 4/128...\n",
      "Processing Batch 5/128...\n",
      "Processing Batch 6/128...\n",
      "Processing Batch 7/128...\n",
      "Processing Batch 8/128...\n",
      "Processing Batch 9/128...\n",
      "Processing Batch 10/128...\n",
      "âœ… Epoch 3/5, Batch 10/128, Loss: 1.2865\n",
      "Processing Batch 11/128...\n",
      "Processing Batch 12/128...\n",
      "Processing Batch 13/128...\n",
      "Processing Batch 14/128...\n",
      "Processing Batch 15/128...\n",
      "Processing Batch 16/128...\n",
      "Processing Batch 17/128...\n",
      "Processing Batch 18/128...\n",
      "Processing Batch 19/128...\n",
      "Processing Batch 20/128...\n",
      "âœ… Epoch 3/5, Batch 20/128, Loss: 1.1706\n",
      "Processing Batch 21/128...\n",
      "Processing Batch 22/128...\n",
      "Processing Batch 23/128...\n",
      "Processing Batch 24/128...\n",
      "Processing Batch 25/128...\n",
      "Processing Batch 26/128...\n",
      "Processing Batch 27/128...\n",
      "Processing Batch 28/128...\n",
      "Processing Batch 29/128...\n",
      "Processing Batch 30/128...\n",
      "âœ… Epoch 3/5, Batch 30/128, Loss: 1.2260\n",
      "Processing Batch 31/128...\n",
      "Processing Batch 32/128...\n",
      "Processing Batch 33/128...\n",
      "Processing Batch 34/128...\n",
      "Processing Batch 35/128...\n",
      "Processing Batch 36/128...\n",
      "Processing Batch 37/128...\n",
      "Processing Batch 38/128...\n",
      "Processing Batch 39/128...\n",
      "Processing Batch 40/128...\n",
      "âœ… Epoch 3/5, Batch 40/128, Loss: 0.9322\n",
      "Processing Batch 41/128...\n",
      "Processing Batch 42/128...\n",
      "Processing Batch 43/128...\n",
      "Processing Batch 44/128...\n",
      "Processing Batch 45/128...\n",
      "Processing Batch 46/128...\n",
      "Processing Batch 47/128...\n",
      "Processing Batch 48/128...\n",
      "Processing Batch 49/128...\n",
      "Processing Batch 50/128...\n",
      "âœ… Epoch 3/5, Batch 50/128, Loss: 0.9519\n",
      "Processing Batch 51/128...\n",
      "Processing Batch 52/128...\n",
      "Processing Batch 53/128...\n",
      "Processing Batch 54/128...\n",
      "Processing Batch 55/128...\n",
      "Processing Batch 56/128...\n",
      "Processing Batch 57/128...\n",
      "Processing Batch 58/128...\n",
      "Processing Batch 59/128...\n",
      "Processing Batch 60/128...\n",
      "âœ… Epoch 3/5, Batch 60/128, Loss: 0.8243\n",
      "Processing Batch 61/128...\n",
      "Processing Batch 62/128...\n",
      "Processing Batch 63/128...\n",
      "Processing Batch 64/128...\n",
      "Processing Batch 65/128...\n",
      "Processing Batch 66/128...\n",
      "Processing Batch 67/128...\n",
      "Processing Batch 68/128...\n",
      "Processing Batch 69/128...\n",
      "Processing Batch 70/128...\n",
      "âœ… Epoch 3/5, Batch 70/128, Loss: 0.9213\n",
      "Processing Batch 71/128...\n",
      "Processing Batch 72/128...\n",
      "Processing Batch 73/128...\n",
      "Processing Batch 74/128...\n",
      "Processing Batch 75/128...\n",
      "Processing Batch 76/128...\n",
      "Processing Batch 77/128...\n",
      "Processing Batch 78/128...\n",
      "Processing Batch 79/128...\n",
      "Processing Batch 80/128...\n",
      "âœ… Epoch 3/5, Batch 80/128, Loss: 0.9150\n",
      "Processing Batch 81/128...\n",
      "Processing Batch 82/128...\n",
      "Processing Batch 83/128...\n",
      "Processing Batch 84/128...\n",
      "Processing Batch 85/128...\n",
      "Processing Batch 86/128...\n",
      "Processing Batch 87/128...\n",
      "Processing Batch 88/128...\n",
      "Processing Batch 89/128...\n",
      "Processing Batch 90/128...\n",
      "âœ… Epoch 3/5, Batch 90/128, Loss: 0.8990\n",
      "Processing Batch 91/128...\n",
      "Processing Batch 92/128...\n",
      "Processing Batch 93/128...\n",
      "Processing Batch 94/128...\n",
      "Processing Batch 95/128...\n",
      "Processing Batch 96/128...\n",
      "Processing Batch 97/128...\n",
      "Processing Batch 98/128...\n",
      "Processing Batch 99/128...\n",
      "Processing Batch 100/128...\n",
      "âœ… Epoch 3/5, Batch 100/128, Loss: 0.6666\n",
      "Processing Batch 101/128...\n",
      "Processing Batch 102/128...\n",
      "Processing Batch 103/128...\n",
      "Processing Batch 104/128...\n",
      "Processing Batch 105/128...\n",
      "Processing Batch 106/128...\n",
      "Processing Batch 107/128...\n",
      "Processing Batch 108/128...\n",
      "Processing Batch 109/128...\n",
      "Processing Batch 110/128...\n",
      "âœ… Epoch 3/5, Batch 110/128, Loss: 0.7638\n",
      "Processing Batch 111/128...\n",
      "Processing Batch 112/128...\n",
      "Processing Batch 113/128...\n",
      "Processing Batch 114/128...\n",
      "Processing Batch 115/128...\n",
      "Processing Batch 116/128...\n",
      "Processing Batch 117/128...\n",
      "Processing Batch 118/128...\n",
      "Processing Batch 119/128...\n",
      "Processing Batch 120/128...\n",
      "âœ… Epoch 3/5, Batch 120/128, Loss: 0.6652\n",
      "Processing Batch 121/128...\n",
      "Processing Batch 122/128...\n",
      "Processing Batch 123/128...\n",
      "Processing Batch 124/128...\n",
      "Processing Batch 125/128...\n",
      "Processing Batch 126/128...\n",
      "Processing Batch 127/128...\n",
      "âœ… Epoch 3/5 Completed! Loss: 0.9487, Accuracy: 0.8353\n",
      "âœ… Model checkpoint saved at epoch 3\n",
      "âœ… Epoch 4/5 started.\n",
      "Processing Batch 0/128...\n",
      "âœ… Epoch 4/5, Batch 0/128, Loss: 0.4769\n",
      "Processing Batch 1/128...\n",
      "Processing Batch 2/128...\n",
      "Processing Batch 3/128...\n",
      "Processing Batch 4/128...\n",
      "Processing Batch 5/128...\n",
      "Processing Batch 6/128...\n",
      "Processing Batch 7/128...\n",
      "Processing Batch 8/128...\n",
      "Processing Batch 9/128...\n",
      "Processing Batch 10/128...\n",
      "âœ… Epoch 4/5, Batch 10/128, Loss: 0.3771\n",
      "Processing Batch 11/128...\n",
      "Processing Batch 12/128...\n",
      "Processing Batch 13/128...\n",
      "Processing Batch 14/128...\n",
      "Processing Batch 15/128...\n",
      "Processing Batch 16/128...\n",
      "Processing Batch 17/128...\n",
      "Processing Batch 18/128...\n",
      "Processing Batch 19/128...\n",
      "Processing Batch 20/128...\n",
      "âœ… Epoch 4/5, Batch 20/128, Loss: 0.3609\n",
      "Processing Batch 21/128...\n",
      "Processing Batch 22/128...\n",
      "Processing Batch 23/128...\n",
      "Processing Batch 24/128...\n",
      "Processing Batch 25/128...\n",
      "Processing Batch 26/128...\n",
      "Processing Batch 27/128...\n",
      "Processing Batch 28/128...\n",
      "Processing Batch 29/128...\n",
      "Processing Batch 30/128...\n",
      "âœ… Epoch 4/5, Batch 30/128, Loss: 0.4047\n",
      "Processing Batch 31/128...\n",
      "Processing Batch 32/128...\n",
      "Processing Batch 33/128...\n",
      "Processing Batch 34/128...\n",
      "Processing Batch 35/128...\n",
      "Processing Batch 36/128...\n",
      "Processing Batch 37/128...\n",
      "Processing Batch 38/128...\n",
      "Processing Batch 39/128...\n",
      "Processing Batch 40/128...\n",
      "âœ… Epoch 4/5, Batch 40/128, Loss: 0.2735\n",
      "Processing Batch 41/128...\n",
      "Processing Batch 42/128...\n",
      "Processing Batch 43/128...\n",
      "Processing Batch 44/128...\n",
      "Processing Batch 45/128...\n",
      "Processing Batch 46/128...\n",
      "Processing Batch 47/128...\n",
      "Processing Batch 48/128...\n",
      "Processing Batch 49/128...\n",
      "Processing Batch 50/128...\n",
      "âœ… Epoch 4/5, Batch 50/128, Loss: 0.3121\n",
      "Processing Batch 51/128...\n",
      "Processing Batch 52/128...\n",
      "Processing Batch 53/128...\n",
      "Processing Batch 54/128...\n",
      "Processing Batch 55/128...\n",
      "Processing Batch 56/128...\n",
      "Processing Batch 57/128...\n",
      "Processing Batch 58/128...\n",
      "Processing Batch 59/128...\n",
      "Processing Batch 60/128...\n",
      "âœ… Epoch 4/5, Batch 60/128, Loss: 0.2400\n",
      "Processing Batch 61/128...\n",
      "Processing Batch 62/128...\n",
      "Processing Batch 63/128...\n",
      "Processing Batch 64/128...\n",
      "Processing Batch 65/128...\n",
      "Processing Batch 66/128...\n",
      "Processing Batch 67/128...\n",
      "Processing Batch 68/128...\n",
      "Processing Batch 69/128...\n",
      "Processing Batch 70/128...\n",
      "âœ… Epoch 4/5, Batch 70/128, Loss: 0.3450\n",
      "Processing Batch 71/128...\n",
      "Processing Batch 72/128...\n",
      "Processing Batch 73/128...\n",
      "Processing Batch 74/128...\n",
      "Processing Batch 75/128...\n",
      "Processing Batch 76/128...\n",
      "Processing Batch 77/128...\n",
      "Processing Batch 78/128...\n",
      "Processing Batch 79/128...\n",
      "Processing Batch 80/128...\n",
      "âœ… Epoch 4/5, Batch 80/128, Loss: 0.2434\n",
      "Processing Batch 81/128...\n",
      "Processing Batch 82/128...\n",
      "Processing Batch 83/128...\n",
      "Processing Batch 84/128...\n",
      "Processing Batch 85/128...\n",
      "Processing Batch 86/128...\n",
      "Processing Batch 87/128...\n",
      "Processing Batch 88/128...\n",
      "Processing Batch 89/128...\n",
      "Processing Batch 90/128...\n",
      "âœ… Epoch 4/5, Batch 90/128, Loss: 0.2623\n",
      "Processing Batch 91/128...\n",
      "Processing Batch 92/128...\n",
      "Processing Batch 93/128...\n",
      "Processing Batch 94/128...\n",
      "Processing Batch 95/128...\n",
      "Processing Batch 96/128...\n",
      "Processing Batch 97/128...\n",
      "Processing Batch 98/128...\n",
      "Processing Batch 99/128...\n",
      "Processing Batch 100/128...\n",
      "âœ… Epoch 4/5, Batch 100/128, Loss: 0.3146\n",
      "Processing Batch 101/128...\n",
      "Processing Batch 102/128...\n",
      "Processing Batch 103/128...\n",
      "Processing Batch 104/128...\n",
      "Processing Batch 105/128...\n",
      "Processing Batch 106/128...\n",
      "Processing Batch 107/128...\n",
      "Processing Batch 108/128...\n",
      "Processing Batch 109/128...\n",
      "Processing Batch 110/128...\n",
      "âœ… Epoch 4/5, Batch 110/128, Loss: 0.3215\n",
      "Processing Batch 111/128...\n",
      "Processing Batch 112/128...\n",
      "Processing Batch 113/128...\n",
      "Processing Batch 114/128...\n",
      "Processing Batch 115/128...\n",
      "Processing Batch 116/128...\n",
      "Processing Batch 117/128...\n",
      "Processing Batch 118/128...\n",
      "Processing Batch 119/128...\n",
      "Processing Batch 120/128...\n",
      "âœ… Epoch 4/5, Batch 120/128, Loss: 0.2287\n",
      "Processing Batch 121/128...\n",
      "Processing Batch 122/128...\n",
      "Processing Batch 123/128...\n",
      "Processing Batch 124/128...\n",
      "Processing Batch 125/128...\n",
      "Processing Batch 126/128...\n",
      "Processing Batch 127/128...\n",
      "âœ… Epoch 4/5 Completed! Loss: 0.3193, Accuracy: 0.9586\n",
      "âœ… Model checkpoint saved at epoch 4\n",
      "âœ… Epoch 5/5 started.\n",
      "Processing Batch 0/128...\n",
      "âœ… Epoch 5/5, Batch 0/128, Loss: 0.1261\n",
      "Processing Batch 1/128...\n",
      "Processing Batch 2/128...\n",
      "Processing Batch 3/128...\n",
      "Processing Batch 4/128...\n",
      "Processing Batch 5/128...\n",
      "Processing Batch 6/128...\n",
      "Processing Batch 7/128...\n",
      "Processing Batch 8/128...\n",
      "Processing Batch 9/128...\n",
      "Processing Batch 10/128...\n",
      "âœ… Epoch 5/5, Batch 10/128, Loss: 0.1423\n",
      "Processing Batch 11/128...\n",
      "Processing Batch 12/128...\n",
      "Processing Batch 13/128...\n",
      "Processing Batch 14/128...\n",
      "Processing Batch 15/128...\n",
      "Processing Batch 16/128...\n",
      "Processing Batch 17/128...\n",
      "Processing Batch 18/128...\n",
      "Processing Batch 19/128...\n",
      "Processing Batch 20/128...\n",
      "âœ… Epoch 5/5, Batch 20/128, Loss: 0.1036\n",
      "Processing Batch 21/128...\n",
      "Processing Batch 22/128...\n",
      "Processing Batch 23/128...\n",
      "Processing Batch 24/128...\n",
      "Processing Batch 25/128...\n",
      "Processing Batch 26/128...\n",
      "Processing Batch 27/128...\n",
      "Processing Batch 28/128...\n",
      "Processing Batch 29/128...\n",
      "Processing Batch 30/128...\n",
      "âœ… Epoch 5/5, Batch 30/128, Loss: 0.1092\n",
      "Processing Batch 31/128...\n",
      "Processing Batch 32/128...\n",
      "Processing Batch 33/128...\n",
      "Processing Batch 34/128...\n",
      "Processing Batch 35/128...\n",
      "Processing Batch 36/128...\n",
      "Processing Batch 37/128...\n",
      "Processing Batch 38/128...\n",
      "Processing Batch 39/128...\n",
      "Processing Batch 40/128...\n",
      "âœ… Epoch 5/5, Batch 40/128, Loss: 0.1121\n",
      "Processing Batch 41/128...\n",
      "Processing Batch 42/128...\n",
      "Processing Batch 43/128...\n",
      "Processing Batch 44/128...\n",
      "Processing Batch 45/128...\n",
      "Processing Batch 46/128...\n",
      "Processing Batch 47/128...\n",
      "Processing Batch 48/128...\n",
      "Processing Batch 49/128...\n",
      "Processing Batch 50/128...\n",
      "âœ… Epoch 5/5, Batch 50/128, Loss: 0.1169\n",
      "Processing Batch 51/128...\n",
      "Processing Batch 52/128...\n",
      "Processing Batch 53/128...\n",
      "Processing Batch 54/128...\n",
      "Processing Batch 55/128...\n",
      "Processing Batch 56/128...\n",
      "Processing Batch 57/128...\n",
      "Processing Batch 58/128...\n",
      "Processing Batch 59/128...\n",
      "Processing Batch 60/128...\n",
      "âœ… Epoch 5/5, Batch 60/128, Loss: 0.1040\n",
      "Processing Batch 61/128...\n",
      "Processing Batch 62/128...\n",
      "Processing Batch 63/128...\n",
      "Processing Batch 64/128...\n",
      "Processing Batch 65/128...\n",
      "Processing Batch 66/128...\n",
      "Processing Batch 67/128...\n",
      "Processing Batch 68/128...\n",
      "Processing Batch 69/128...\n",
      "Processing Batch 70/128...\n",
      "âœ… Epoch 5/5, Batch 70/128, Loss: 0.1653\n",
      "Processing Batch 71/128...\n",
      "Processing Batch 72/128...\n",
      "Processing Batch 73/128...\n",
      "Processing Batch 74/128...\n",
      "Processing Batch 75/128...\n",
      "Processing Batch 76/128...\n",
      "Processing Batch 77/128...\n",
      "Processing Batch 78/128...\n",
      "Processing Batch 79/128...\n",
      "Processing Batch 80/128...\n",
      "âœ… Epoch 5/5, Batch 80/128, Loss: 0.0800\n",
      "Processing Batch 81/128...\n",
      "Processing Batch 82/128...\n",
      "Processing Batch 83/128...\n",
      "Processing Batch 84/128...\n",
      "Processing Batch 85/128...\n",
      "Processing Batch 86/128...\n",
      "Processing Batch 87/128...\n",
      "Processing Batch 88/128...\n",
      "Processing Batch 89/128...\n",
      "Processing Batch 90/128...\n",
      "âœ… Epoch 5/5, Batch 90/128, Loss: 0.0774\n",
      "Processing Batch 91/128...\n",
      "Processing Batch 92/128...\n",
      "Processing Batch 93/128...\n",
      "Processing Batch 94/128...\n",
      "Processing Batch 95/128...\n",
      "Processing Batch 96/128...\n",
      "Processing Batch 97/128...\n",
      "Processing Batch 98/128...\n",
      "Processing Batch 99/128...\n",
      "Processing Batch 100/128...\n",
      "âœ… Epoch 5/5, Batch 100/128, Loss: 0.1199\n",
      "Processing Batch 101/128...\n",
      "Processing Batch 102/128...\n",
      "Processing Batch 103/128...\n",
      "Processing Batch 104/128...\n",
      "Processing Batch 105/128...\n",
      "Processing Batch 106/128...\n",
      "Processing Batch 107/128...\n",
      "Processing Batch 108/128...\n",
      "Processing Batch 109/128...\n",
      "Processing Batch 110/128...\n",
      "âœ… Epoch 5/5, Batch 110/128, Loss: 0.1110\n",
      "Processing Batch 111/128...\n",
      "Processing Batch 112/128...\n",
      "Processing Batch 113/128...\n",
      "Processing Batch 114/128...\n",
      "Processing Batch 115/128...\n",
      "Processing Batch 116/128...\n",
      "Processing Batch 117/128...\n",
      "Processing Batch 118/128...\n",
      "Processing Batch 119/128...\n",
      "Processing Batch 120/128...\n",
      "âœ… Epoch 5/5, Batch 120/128, Loss: 0.0900\n",
      "Processing Batch 121/128...\n",
      "Processing Batch 122/128...\n",
      "Processing Batch 123/128...\n",
      "Processing Batch 124/128...\n",
      "Processing Batch 125/128...\n",
      "Processing Batch 126/128...\n",
      "Processing Batch 127/128...\n",
      "âœ… Epoch 5/5 Completed! Loss: 0.1103, Accuracy: 0.9917\n",
      "âœ… Model checkpoint saved at epoch 5\n",
      "âœ… Training Completed!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#  ×˜×¢×™× ×ª ResNet50 ×¢× ×”×ª×××” ×œ-Cars196\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, len(set(label for _, label in train_data)))  # ××¡×¤×¨ ×”××—×œ×§×•×ª\n",
    "model = model.to(device)\n",
    "\n",
    "#  ×¤×•× ×§×¦×™×™×ª ×”×¤×¡×“ (Loss) ×•××•×¤×˜×™××™×–×¦×™×”\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "#  ××™××•×Ÿ ×”×¨×©×ª\n",
    "print(\" Starting training...\")\n",
    "num_epochs = 5  \n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    print(f\" Epoch {epoch+1}/{num_epochs} started.\")  # ğŸ›  ×”×× ×‘×›×œ×œ ×”×ª×—×™×œ ××™××•×Ÿ?\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        print(f\"Processing Batch {batch_idx}/{len(train_loader)}...\")  # ğŸ›  ×‘×“×™×§×” ×œ×¤× ×™ ×”×¢×‘×¨×ª ×”× ×ª×•× ×™× ×œ××•×“×œ\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        #  ×¢×“×›×•×Ÿ ×›×œ 10 ×‘××¦'×™× (×¡×˜×˜×•×¡ ×‘×™× ×™×™×)\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\" Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    print(f\" Epoch {epoch+1}/{num_epochs} Completed! Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    #  ×”×•×¡×¤×ª Checkpoint ×©××™×¨×” ×‘×›×œ ×¡×•×£ Epoch\n",
    "    torch.save(model.state_dict(), f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "    print(f\" Model checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "print(\" Training Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "217ab7e5-a6e3-4116-965f-29c22cd60dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ×˜×¢×™× ×ª ×”××•×“×œ ×”×××•××Ÿ ×•×”×›× ×ª FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "833fe4b4-cc61-4327-a902-61d747221b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revit\\AppData\\Local\\Temp\\ipykernel_10124\\1072647916.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(\"C:\\\\Users\\\\revit\\\\Documents\\\\Data Learning\\\\Project2\", last_checkpoint), map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded from last checkpoint (Epoch 5).\n"
     ]
    }
   ],
   "source": [
    "last_checkpoint = \"checkpoint_epoch_5.pth\"\n",
    "model.load_state_dict(torch.load(os.path.join(\"C:\\\\Users\\\\revit\\\\Documents\\\\Data Learning\\\\Project2\", last_checkpoint), map_location=device))\n",
    "print(\" Model loaded from last checkpoint (Epoch 5).\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25f505d4-eef8-4461-8b1e-ff39aaba2e4e",
   "metadata": {},
   "source": [
    "#  ×˜×¢×™× ×ª ×”××•×“×œ ×”×××•××Ÿ ×œ×”×¡×¨×ª ×©×›×‘×ª ×”×¡×™×•×•×’\n",
    "model.load_state_dict(torch.load(\"fine_tuned_resnet50_cars196.pth\", map_location=device))\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # ×”×¡×¨×ª ×©×›×‘×ª ×”×¡×™×•×•×’\n",
    "model.eval()\n",
    "\n",
    "#  ×¤×•× ×§×¦×™×” ×œ×—×™×œ×•×¥ ×××¤×™×™× ×™×\n",
    "def extract_features(image):\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.squeeze().cpu().numpy()\n",
    "\n",
    "#  ×™×¦×™×¨×ª FAISS\n",
    "index = faiss.IndexFlatL2(2048)\n",
    "all_features, image_data_list = [], []\n",
    "\n",
    "for image_np, label in train_data:\n",
    "    pil_image = Image.fromarray(image_np)\n",
    "    feature_vector = extract_features(pil_image)\n",
    "    all_features.append(feature_vector)\n",
    "    image_data_list.append((pil_image, label))\n",
    "\n",
    "all_features = np.array(all_features).astype('float32')\n",
    "faiss.normalize_L2(all_features)\n",
    "index.add(all_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c76603-96d3-4207-9110-c75d24717ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ×—×™×¤×•×© ×ª××•× ×•×ª ×“×•××•×ª ×•×”×¢×¨×›×ª ××™×›×•×ª"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c812008-98d2-435e-a3f9-54fa0d116b29",
   "metadata": {},
   "source": [
    "#  ×¤×•× ×§×¦×™×” ×œ×—×™×¤×•×© ×“××™×•×Ÿ\n",
    "def search_similar(image, index, k=5):\n",
    "    query_vector = extract_features(image).reshape(1, -1).astype('float32')\n",
    "    faiss.normalize_L2(query_vector)\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "    return indices[0], distances\n",
    "\n",
    "#  ×‘×—×™×¨×ª ×ª××•× ×” ×œ×‘×“×™×§×”\n",
    "query_image_np, query_label = test_data[0]\n",
    "query_pil_image = Image.fromarray(query_image_np)\n",
    "\n",
    "# ğŸ”¹ ×—×™×¤×•×© ×ª××•× ×•×ª ×“×•××•×ª\n",
    "similar_images, distances = search_similar(query_pil_image, index, k=5)\n",
    "\n",
    "# ğŸ”¹ ×”×¦×’×ª ×ª×•×¦××•×ª\n",
    "def show_results(query_image, similar_indices, distances):\n",
    "    fig, ax = plt.subplots(1, 6, figsize=(15, 5))\n",
    "    ax[0].imshow(query_image)\n",
    "    ax[0].set_title(\"Query Image\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    for i, (idx, dist) in enumerate(zip(similar_indices, distances[0])):\n",
    "        similar_pil_image, _ = image_data_list[idx]\n",
    "        ax[i+1].imshow(similar_pil_image)\n",
    "        ax[i+1].set_title(f\"Match {i+1} (Score: {dist:.2f})\")\n",
    "        ax[i+1].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_results(query_pil_image, similar_images, distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de13afed-1887-486d-a0c3-6cbd36bb69bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Classification layer removed. Model ready for feature extraction.\n"
     ]
    }
   ],
   "source": [
    "# ×”×¡×¨×ª ×©×›×‘×ª ×¡×™×•×•×’ ×•×—×™×œ×•×ª ×××¤×¤×™×™× ×™×¤\n",
    "#  ×”×¡×¨×ª ×©×›×‘×ª ×”×¡×™×•×•×’\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # ××©××™×¨×™× ×¨×§ ××ª ×”-Feature Extractor\n",
    "model.eval()\n",
    "print(\" Classification layer removed. Model ready for feature extraction.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2d458e6-1bf9-43bd-aca3-c7b58a1ee175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ×¤×•× ×§×¦×™×” ×œ×—×™×œ×•×¥ ×××¤×™×™× ×™×\n",
    "def extract_features(image):\n",
    "    image = transform(image).unsqueeze(0).to(device)  # ×”××¨×” ×œ×˜× ×¡×•×¨ ×•×”×•×¡×¤×ª Batch Dimension\n",
    "    with torch.no_grad():\n",
    "        features = model(image)  # ×”×¨×¦×ª ×”××•×“×œ\n",
    "    return features.squeeze().cpu().numpy()  # ×”××¨×” ×œ-NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e2d35e3-eadc-44ce-92fd-828be815fd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test Accuracy: 0.0313\n"
     ]
    }
   ],
   "source": [
    "#  ×©×œ×‘ ×‘×“×™×§×ª ×”×‘×™×¦×•×¢×™× ×¢×œ ×”-Test Set\n",
    "model.eval()  # ××¢×‘×™×¨ ××ª ×”××•×“×œ ×œ××¦×‘ ×”×¢×¨×›×” (Evaluation)\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():  # ××™×Ÿ ×¦×•×¨×š ×œ×—×©×‘ ×’×¨×“×™×× ×˜×™× ×‘×‘×“×™×§×”\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # ×‘×•×—×¨×™× ××ª ×”××—×œ×§×” ×¢× ×”×¡×™×›×•×™ ×”×’×‘×•×” ×‘×™×•×ª×¨\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_accuracy = correct / total  # ×—×™×©×•×‘ ×”×“×™×•×§ ×”×¡×•×¤×™\n",
    "print(f\" Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "565fb533-2ec0-4cb4-abf5-e2ac52873779",
   "metadata": {},
   "source": [
    "×‘×¢×™×” ×—××•×¨×” ×©×œ Overfitting!\n",
    " Test Accuracy = 3.13% ×œ×¢×•××ª Train Accuracy = 99.17% â†’\n",
    " ×–×” ×¡×™××Ÿ ××•×‘×”×§ ×©×”××•×“×œ ×œ××“ ×œ×©× ×Ÿ ××ª ×”×“××˜×” ×•×œ× ×œ×‘×¦×¢ ×”×›×œ×œ×”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95809477-b0c2-4113-b5d9-d9c6055c7ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ×™×¦×™×¨×ª ××™× ×“×§×¡ FAISS ×œ×›×œ ×”×ª××•× ×•×ª ×‘-Train\n",
    "import faiss\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "index = faiss.IndexFlatL2(2048)  # FAISS Index - ×—×™×¤×•×© ×œ×¤×™ L2 Distance\n",
    "all_features, image_data_list = [], []\n",
    "\n",
    "for image_np, label in train_data:\n",
    "    pil_image = Image.fromarray(image_np)  # ×”××¨×ª NumPy ×œ-PIL\n",
    "    feature_vector = extract_features(pil_image)  # ×—×™×œ×•×¥ ×××¤×™×™× ×™×\n",
    "    all_features.append(feature_vector)\n",
    "    image_data_list.append((pil_image, label))  # ×©××™×¨×ª ×”×ª××•× ×” ×•×”×ª×’×™×ª ×©×œ×”\n",
    "\n",
    "#  × ×•×¨××œ×™×–×¦×™×” ×•×©××™×¨×ª ×•×§×˜×•×¨×™× ×‘××™× ×“×§×¡ FAISS\n",
    "all_features = np.array(all_features).astype('float32')\n",
    "faiss.normalize_L2(all_features)\n",
    "index.add(all_features)\n",
    "\n",
    "print(f\" FAISS index built with {len(all_features)} images using fine-tuned model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03736aea-22bc-41a5-93c3-71b4115cc88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ×—×™×¤×•×© ×ª××•× ×•×ª ×“×•××•×ª (Image Retrieval)\n",
    "#  ×‘×—×™×¨×ª ×ª××•× ×” ×œ×‘×“×™×§×”\n",
    "query_image_np, query_label = test_data[0]\n",
    "query_pil_image = Image.fromarray(query_image_np)\n",
    "\n",
    "#  ×—×™×¤×•×© ×ª××•× ×•×ª ×“×•××•×ª ×‘-FAISS\n",
    "def search_similar(image, index, k=5):\n",
    "    query_vector = extract_features(image).reshape(1, -1).astype('float32')\n",
    "    faiss.normalize_L2(query_vector)\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "    return indices[0], distances\n",
    "\n",
    "similar_images, distances = search_similar(query_pil_image, index, k=5)\n",
    "\n",
    "print(\" Similar images found at indices:\", similar_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4493b6-1282-4418-b61a-15a2f96c2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ×”×¦×’×ª ×”×ª×•×¦××•×ª\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_results(query_image, similar_indices, distances):\n",
    "    fig, ax = plt.subplots(1, 6, figsize=(15, 5))\n",
    "    ax[0].imshow(query_image)\n",
    "    ax[0].set_title(\"Query Image\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    for i, (idx, dist) in enumerate(zip(similar_indices, distances[0])):\n",
    "        similar_pil_image, _ = image_data_list[idx]\n",
    "        ax[i+1].imshow(similar_pil_image)\n",
    "        ax[i+1].set_title(f\"Match {i+1} (Score: {dist:.2f})\")\n",
    "        ax[i+1].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_results(query_pil_image, similar_images, distances)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
